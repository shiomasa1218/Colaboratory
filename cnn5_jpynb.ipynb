{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn5.jpynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shiomasa1218/Colaboratory/blob/master/cnn5_jpynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "sy7vnrkJTAvc",
        "colab_type": "code",
        "outputId": "222d11ff-4941-4c27-b060-7840662e5ad3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "n3zaYFw8TD45",
        "colab_type": "code",
        "outputId": "8734fb7f-be45-4f86-d3b9-320ff55b1016",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# drive mean root directory of  google drive\n",
        "!ls ./gdrive/'My Drive'/'Kumamoto-Univ'/'Graduationwork'/'exefolder'/'train_folder_name'"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: Transport endpoint is not connected\n",
            "ls: cannot access './gdrive/My Drive/Kumamoto-Univ/Graduationwork/exefolder/train_folder_name': Transport endpoint is not connected\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kCG948Ygb1Yo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "bf50f29d-fdb6-4e10-a3dc-f08747ae74e2"
      },
      "cell_type": "code",
      "source": [
        "# This only needs to be done once per notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# check auth\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K    1% |▎                               | 10kB 17.1MB/s eta 0:00:01\r\u001b[K    2% |▋                               | 20kB 2.4MB/s eta 0:00:01\r\u001b[K    3% |█                               | 30kB 3.4MB/s eta 0:00:01\r\u001b[K    4% |█▎                              | 40kB 2.2MB/s eta 0:00:01\r\u001b[K    5% |█▋                              | 51kB 2.7MB/s eta 0:00:01\r\u001b[K    6% |██                              | 61kB 3.2MB/s eta 0:00:01\r\u001b[K    7% |██▎                             | 71kB 3.7MB/s eta 0:00:01\r\u001b[K    8% |██▋                             | 81kB 4.2MB/s eta 0:00:01\r\u001b[K    9% |███                             | 92kB 4.6MB/s eta 0:00:01\r\u001b[K    10% |███▎                            | 102kB 3.6MB/s eta 0:00:01\r\u001b[K    11% |███▋                            | 112kB 3.6MB/s eta 0:00:01\r\u001b[K    12% |████                            | 122kB 4.9MB/s eta 0:00:01\r\u001b[K    13% |████▎                           | 133kB 4.9MB/s eta 0:00:01\r\u001b[K    14% |████▋                           | 143kB 9.0MB/s eta 0:00:01\r\u001b[K    15% |█████                           | 153kB 9.2MB/s eta 0:00:01\r\u001b[K    16% |█████▎                          | 163kB 9.1MB/s eta 0:00:01\r\u001b[K    17% |█████▋                          | 174kB 9.0MB/s eta 0:00:01\r\u001b[K    18% |██████                          | 184kB 9.0MB/s eta 0:00:01\r\u001b[K    19% |██████▎                         | 194kB 9.0MB/s eta 0:00:01\r\u001b[K    20% |██████▋                         | 204kB 35.8MB/s eta 0:00:01\r\u001b[K    21% |███████                         | 215kB 10.7MB/s eta 0:00:01\r\u001b[K    22% |███████▎                        | 225kB 10.6MB/s eta 0:00:01\r\u001b[K    23% |███████▋                        | 235kB 10.7MB/s eta 0:00:01\r\u001b[K    24% |████████                        | 245kB 10.6MB/s eta 0:00:01\r\u001b[K    25% |████████▎                       | 256kB 10.6MB/s eta 0:00:01\r\u001b[K    26% |████████▋                       | 266kB 10.3MB/s eta 0:00:01\r\u001b[K    27% |█████████                       | 276kB 10.6MB/s eta 0:00:01\r\u001b[K    29% |█████████▎                      | 286kB 10.6MB/s eta 0:00:01\r\u001b[K    30% |█████████▋                      | 296kB 10.6MB/s eta 0:00:01\r\u001b[K    31% |██████████                      | 307kB 10.8MB/s eta 0:00:01\r\u001b[K    32% |██████████▎                     | 317kB 40.9MB/s eta 0:00:01\r\u001b[K    33% |██████████▋                     | 327kB 42.5MB/s eta 0:00:01\r\u001b[K    34% |███████████                     | 337kB 43.2MB/s eta 0:00:01\r\u001b[K    35% |███████████▎                    | 348kB 40.6MB/s eta 0:00:01\r\u001b[K    36% |███████████▋                    | 358kB 40.8MB/s eta 0:00:01\r\u001b[K    37% |████████████                    | 368kB 46.4MB/s eta 0:00:01\r\u001b[K    38% |████████████▎                   | 378kB 45.6MB/s eta 0:00:01\r\u001b[K    39% |████████████▋                   | 389kB 46.4MB/s eta 0:00:01\r\u001b[K    40% |█████████████                   | 399kB 12.9MB/s eta 0:00:01\r\u001b[K    41% |█████████████▎                  | 409kB 12.7MB/s eta 0:00:01\r\u001b[K    42% |█████████████▋                  | 419kB 12.8MB/s eta 0:00:01\r\u001b[K    43% |██████████████                  | 430kB 12.7MB/s eta 0:00:01\r\u001b[K    44% |██████████████▎                 | 440kB 12.7MB/s eta 0:00:01\r\u001b[K    45% |██████████████▋                 | 450kB 12.8MB/s eta 0:00:01\r\u001b[K    46% |███████████████                 | 460kB 12.7MB/s eta 0:00:01\r\u001b[K    47% |███████████████▎                | 471kB 12.7MB/s eta 0:00:01\r\u001b[K    48% |███████████████▋                | 481kB 12.7MB/s eta 0:00:01\r\u001b[K    49% |████████████████                | 491kB 12.7MB/s eta 0:00:01\r\u001b[K    50% |████████████████▎               | 501kB 44.0MB/s eta 0:00:01\r\u001b[K    51% |████████████████▋               | 512kB 42.3MB/s eta 0:00:01\r\u001b[K    52% |█████████████████               | 522kB 42.3MB/s eta 0:00:01\r\u001b[K    53% |█████████████████▎              | 532kB 44.1MB/s eta 0:00:01\r\u001b[K    54% |█████████████████▋              | 542kB 44.0MB/s eta 0:00:01\r\u001b[K    55% |██████████████████              | 552kB 48.2MB/s eta 0:00:01\r\u001b[K    57% |██████████████████▎             | 563kB 48.3MB/s eta 0:00:01\r\u001b[K    58% |██████████████████▋             | 573kB 47.3MB/s eta 0:00:01\r\u001b[K    59% |███████████████████             | 583kB 47.6MB/s eta 0:00:01\r\u001b[K    60% |███████████████████▎            | 593kB 48.1MB/s eta 0:00:01\r\u001b[K    61% |███████████████████▋            | 604kB 48.3MB/s eta 0:00:01\r\u001b[K    62% |████████████████████            | 614kB 52.5MB/s eta 0:00:01\r\u001b[K    63% |████████████████████▎           | 624kB 51.6MB/s eta 0:00:01\r\u001b[K    64% |████████████████████▋           | 634kB 50.9MB/s eta 0:00:01\r\u001b[K    65% |█████████████████████           | 645kB 49.6MB/s eta 0:00:01\r\u001b[K    66% |█████████████████████▎          | 655kB 48.2MB/s eta 0:00:01\r\u001b[K    67% |█████████████████████▋          | 665kB 38.6MB/s eta 0:00:01\r\u001b[K    68% |██████████████████████          | 675kB 39.6MB/s eta 0:00:01\r\u001b[K    69% |██████████████████████▎         | 686kB 39.6MB/s eta 0:00:01\r\u001b[K    70% |██████████████████████▋         | 696kB 39.5MB/s eta 0:00:01\r\u001b[K    71% |███████████████████████         | 706kB 39.3MB/s eta 0:00:01\r\u001b[K    72% |███████████████████████▎        | 716kB 39.7MB/s eta 0:00:01\r\u001b[K    73% |███████████████████████▋        | 727kB 39.8MB/s eta 0:00:01\r\u001b[K    74% |████████████████████████        | 737kB 21.3MB/s eta 0:00:01\r\u001b[K    75% |████████████████████████▎       | 747kB 21.5MB/s eta 0:00:01\r\u001b[K    76% |████████████████████████▋       | 757kB 21.6MB/s eta 0:00:01\r\u001b[K    77% |████████████████████████▉       | 768kB 24.4MB/s eta 0:00:01\r\u001b[K    78% |█████████████████████████▏      | 778kB 24.4MB/s eta 0:00:01\r\u001b[K    79% |█████████████████████████▌      | 788kB 24.1MB/s eta 0:00:01\r\u001b[K    80% |█████████████████████████▉      | 798kB 24.1MB/s eta 0:00:01\r\u001b[K    81% |██████████████████████████▏     | 808kB 24.0MB/s eta 0:00:01\r\u001b[K    82% |██████████████████████████▌     | 819kB 23.9MB/s eta 0:00:01\r\u001b[K    83% |██████████████████████████▉     | 829kB 23.9MB/s eta 0:00:01\r\u001b[K    85% |███████████████████████████▏    | 839kB 49.2MB/s eta 0:00:01\r\u001b[K    86% |███████████████████████████▌    | 849kB 49.8MB/s eta 0:00:01\r\u001b[K    87% |███████████████████████████▉    | 860kB 43.2MB/s eta 0:00:01\r\u001b[K    88% |████████████████████████████▏   | 870kB 42.6MB/s eta 0:00:01\r\u001b[K    89% |████████████████████████████▌   | 880kB 42.9MB/s eta 0:00:01\r\u001b[K    90% |████████████████████████████▉   | 890kB 44.3MB/s eta 0:00:01\r\u001b[K    91% |█████████████████████████████▏  | 901kB 43.8MB/s eta 0:00:01\r\u001b[K    92% |█████████████████████████████▌  | 911kB 43.7MB/s eta 0:00:01\r\u001b[K    93% |█████████████████████████████▉  | 921kB 43.5MB/s eta 0:00:01\r\u001b[K    94% |██████████████████████████████▏ | 931kB 43.4MB/s eta 0:00:01\r\u001b[K    95% |██████████████████████████████▌ | 942kB 44.2MB/s eta 0:00:01\r\u001b[K    96% |██████████████████████████████▉ | 952kB 44.4MB/s eta 0:00:01\r\u001b[K    97% |███████████████████████████████▏| 962kB 51.9MB/s eta 0:00:01\r\u001b[K    98% |███████████████████████████████▌| 972kB 53.0MB/s eta 0:00:01\r\u001b[K    99% |███████████████████████████████▉| 983kB 52.7MB/s eta 0:00:01\r\u001b[K    100% |████████████████████████████████| 993kB 17.7MB/s \n",
            "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rene0CrV09pI",
        "colab_type": "code",
        "outputId": "718d0749-82c0-4616-affc-6d0625f78396",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "cd gdrive/'My Drive'/'Kumamoto-Univ'/'Graduationwork'/'exefolder'/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Kumamoto-Univ/Graduationwork/exefolder\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "G1Kqbaml1EtG",
        "colab_type": "code",
        "outputId": "b066bed2-62eb-467c-fe4f-d643abdc2127",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cnn5.py    input_data.py  __pycache__  test_folder_name\n",
            "dft321.py  log.csv\t  result.txt   train_folder_name\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7MdwmGqtcdDZ",
        "colab_type": "code",
        "outputId": "61321660-eec6-45b4-f5ae-f5bdcb46b9af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 9931
        }
      },
      "cell_type": "code",
      "source": [
        "#CNNの実装\n",
        "\n",
        "#python3の文法を2系で使うためのコマンド\n",
        "#from __future__ import absolute_import, unicode_literals\n",
        "\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import csv\n",
        "import pandas as pd\n",
        "import input_data\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import datetime\n",
        "from sklearn.metrics import confusion_matrix,recall_score,precision_score,f1_score\n",
        "#import serial\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "#フィルタ作成\n",
        "def weight_variable(shape):\n",
        "\n",
        "    #initial = tf.truncated_normal(shape, stddev=np.sqrt(2.0/(shape[0]*shape[1]*shape[3])))\n",
        "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
        "    # #initial = tf.random_uniform(minval= -1.0, maxval=1.0)\n",
        "    return tf.Variable(initial)\n",
        "\n",
        "def weight_variable_he(shape,nodes):\n",
        "    initial = tf.truncated_normal(shape, stddev=np.sqrt(2.0/nodes))\n",
        "    # initial = tf.random_uniform(minval= -1.0, maxval=1.0)\n",
        "    return tf.Variable(initial)\n",
        "\n",
        "\n",
        "#バイアス作成\n",
        "def bias_variable(shape):\n",
        "    initial = tf.constant(0.1, shape=shape)\n",
        "    return tf.Variable(initial)\n",
        "\n",
        "\n",
        "def conv2d(x,W):\n",
        "    return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding='VALID')\n",
        "\n",
        "def max_pool_2x2(x):\n",
        "    return tf.nn.max_pool(x, ksize = [1,1,2,1], strides=[1,1,2,1],padding = 'VALID')\n",
        "\n",
        "def batch_normalization(shape, input):\n",
        "    eps = 1e-5\n",
        "    gamma = weight_variable([shape])\n",
        "    beta = weight_variable([shape])\n",
        "    mean,variance = tf.nn.moments(input,[0])\n",
        "    return gamma * (input - mean) / tf.sqrt(variance+eps) + beta\n",
        "\n",
        "def Activation(x):\n",
        "    datas = tf.nn.relu(x)\n",
        "    #datas = tf.nn.tanh(x)\n",
        "    return datas\n",
        "\n",
        "\n",
        "#----------------\n",
        "#  データの読み込み\n",
        "#----------------\n",
        "\n",
        "\n",
        "Data_Classes = 8 #学習クラス数\n",
        "steps = 5000 #ミニバッチ学習回数\n",
        "BATCH_SIZE = 1000 #ミニバッチの一回の学習で使う量\n",
        "#TBATCH_SIZE = 10\n",
        "# Validation = 0.8  #  ここの値で分割 ex. Validation = 0.4 →　0.4:0.6　に分割\n",
        "CaptureNumber = 200 #ミニバッチの大きさ、初期は２００個のデータ\n",
        "drop = 1.0 #dropoutの係数、NNのノードがこれをかけた数になる\n",
        "\n",
        "allCSize = 4608 #全結合サイズ\n",
        "filterSize = 64 #畳みこみフィルタ（カーネル）サイズ 今回は 1 x filiterSize の大きさ\n",
        "\n",
        "\n",
        "# 訓練データのフォルダのパス\n",
        "train_folder_name = \"train_folder_name\"\n",
        "# 検証データのフォルダのパス\n",
        "#test_folder_name = \"test_folder_name\"\n",
        "\n",
        "# train_dir_name = ['pbldatas/d2','pbldatas/d3','pbldatas/d4']\n",
        "# Ex_filename = [\"carpet1\",\"carpet2\",\"carpet3\",\"sponge_g\",\"sponge_y\",\"stonetile1\",\"stonetile2\",\"whitetile2\",\"whitetile1\",\"woodtile1\"]\n",
        "\n",
        "#全訓練データとそのラベル\n",
        "All_Datas = []\n",
        "All_Label = []\n",
        "\n",
        "#外部検証データとそのラベル\n",
        "Ex_TestDatas=[]\n",
        "Ex_Label = []\n",
        "\n",
        "#並び順をシャッフルしたあとの訓練データ\n",
        "All_SDatas =[]\n",
        "All_SLabel = []\n",
        "\n",
        "#分割後の訓練データ，学習するほう\n",
        "train_data = []\n",
        "train_label = []\n",
        "\n",
        "#分割後の訓練データ，モデル評価するほう\n",
        "test_data = []\n",
        "test_label = []\n",
        "\n",
        "#フォルダ中身のファイル名を取得\n",
        "Folder = os.listdir(train_folder_name)\n",
        "# Folder2 = os.listdir(test_folder_name)\n",
        "\n",
        "\n",
        "# .DS_Storeがあるか検知\n",
        "dsflag = 0\n",
        "\n",
        "if Folder[0] == \".DS_Store\":\n",
        "    Data_Classes = len(Folder)-1\n",
        "    print(\"DS!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
        "    dsflag = dsflag + 1\n",
        "else:\n",
        "    Data_Classes = len(Folder)\n",
        "\n",
        "print(dsflag)\n",
        "print(Data_Classes)\n",
        "print(train_folder_name)\n",
        "\n",
        "#フォルダごとにみる\n",
        "#訓練データの読み込み\n",
        "for i,d in enumerate(Folder):\n",
        "    if d != \".DS_Store\":\n",
        "        #フォルダ内のファイルのリストを取得\n",
        "        files = os.listdir(train_folder_name + '/'+d)\n",
        "        print(files)\n",
        "\n",
        "        # Ex_filename.append(d)\n",
        "\n",
        "        #ファイル毎にみる\n",
        "        for f in files:\n",
        "\n",
        "            #.DS_Storeをどかす\n",
        "            if f != \".DS_Store\":\n",
        "                #どのファイルを見ているか確認用\n",
        "                #print(\"load:\"+f)\n",
        "\n",
        "                datafile_path = train_folder_name + '/' + d+'/'+f\n",
        "\n",
        "                #csvから読み込み\n",
        "                data = np.loadtxt(datafile_path, delimiter=\",\")     #pbldata用\n",
        "                datalen = data[0,:].size\n",
        "\n",
        "                #3x200のデータに整形\n",
        "                x_csv = data[0, :]\n",
        "                y_csv = data[1, :]\n",
        "                z_csv = data[2, :]\n",
        "\n",
        "                flatdata = []\n",
        "                flatdata.append(x_csv)\n",
        "                flatdata.append(y_csv)\n",
        "                flatdata.append(z_csv)\n",
        "\n",
        "                All_Datas.append(flatdata)\n",
        "\n",
        "                #one_hot_vectorを作成し，ラベルとしてtrain_labelに追加\n",
        "                tmp = np.zeros(Data_Classes)\n",
        "                if dsflag == 0:\n",
        "                    tmp[i] = 1\n",
        "                else:\n",
        "                    tmp[i-1] = 1\n",
        "                All_Label.append(tmp)\n",
        "            else:\n",
        "                print(\".ds_storeを除去\")\n",
        "    else:\n",
        "        print(\"ds_storeを抹殺\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 検証データの読み込み\n",
        "# for i, d in enumerate(Folder2):\n",
        "#     if d != \".DS_Store\":\n",
        "#         # フォルダ内のファイルのリストを取得\n",
        "#         files = os.listdir(test_folder_name + '/' + d)\n",
        "#         print(files)\n",
        "#\n",
        "#         # ファイル毎にみる\n",
        "#\n",
        "#         count1 = 0\n",
        "#\n",
        "#         for f in files:\n",
        "#\n",
        "#             # .DS_Storeをどかす\n",
        "#             if f != \".DS_Store\":\n",
        "#                 # どのファイルを見ているか確認用\n",
        "#                 # print(\"load:\"+f)\n",
        "#                 datafile_path = test_folder_name + '/' + d + '/' + f\n",
        "#                 # csvから読み込み\n",
        "#                 data = np.loadtxt(datafile_path, delimiter=\",\")     #pbldata用\n",
        "#                 datalen = data[0, :].size\n",
        "#                 # print(datalen)\n",
        "#\n",
        "#                 x_csv = data[0, :]\n",
        "#                 y_csv = data[1, :]\n",
        "#                 z_csv = data[2, :]\n",
        "#\n",
        "#                 x_200 = x_csv[400:600]\n",
        "#                 y_200 = y_csv[400:600]\n",
        "#                 z_200 = z_csv[400:600]\n",
        "#\n",
        "#                 flatdata = []\n",
        "#                 flatdata.append(x_200)\n",
        "#                 flatdata.append(y_200)\n",
        "#                 flatdata.append(z_200)\n",
        "#\n",
        "#                 Ex_TestDatas.append(flatdata)\n",
        "#\n",
        "#                 tmp = np.zeros(Data_Classes)\n",
        "#                 if dsflag == 0:\n",
        "#                     print('on')\n",
        "#                     print(count1)\n",
        "#                     tmp[count1] = 1\n",
        "#                     print(tmp)\n",
        "#                 else:\n",
        "#                     print('off')\n",
        "#                     print(count1)\n",
        "#                     tmp[count1 - 1] = 1\n",
        "#                     print(tmp)\n",
        "#\n",
        "#                 Ex_Label.append(tmp)\n",
        "#\n",
        "#                 #緊急措置　挙動がわからないのでとりあえず\n",
        "#                 count1 = count1+1\n",
        "#\n",
        "#\n",
        "#             else:\n",
        "#                 print(\".ds_storeを除去\")\n",
        "#\n",
        "#     else:\n",
        "#         print(\"ds_storeを抹殺\")\n",
        "#\n",
        "# print(Ex_TestDatas[0])\n",
        "# print(\"Ex_Label\")\n",
        "# print(Ex_Label)\n",
        "\n",
        "#訓練データ順列のシャッフル\n",
        "np.random.seed(seed=32)\n",
        "Rindex = np.random.permutation(list(range(len(All_Datas))))\n",
        "print(Rindex)\n",
        "for k in Rindex:\n",
        "    All_SDatas.append(All_Datas[k])\n",
        "    All_SLabel.append(All_Label[k])\n",
        "\n",
        "\n",
        "#訓練データを学習に使うやつとモデルの評価に使うやつの２種に分ける\n",
        "numberV = int(len(All_SDatas)*(0.9)) #訓練データ数\n",
        "testV = len(All_SDatas) - numberV  #テストデータ数\n",
        "train_data = All_SDatas[:numberV] #0.９まで\n",
        "test_data = All_SDatas[numberV+1:]\n",
        "train_label = All_SLabel[:numberV]\n",
        "test_label = All_SLabel[numberV+1:]\n",
        "\n",
        "\n",
        "print(len(train_data))\n",
        "print(len(test_data))\n",
        "\n",
        "\n",
        "#----------\n",
        "#numpy行列へ\n",
        "#----------\n",
        "train_data = np.array(train_data)\n",
        "train_label = np.array(train_label)\n",
        "\n",
        "test_data = np.array(test_data)\n",
        "test_label = np.array(test_label)\n",
        "\n",
        "#------------\n",
        "#placeholder\n",
        "#-------------\n",
        "\n",
        "sess = tf.InteractiveSession()\n",
        "x = tf.placeholder('float', shape=[None,3,CaptureNumber]) #28x28の画像データ\n",
        "y_ = tf.placeholder('float', shape=[None, Data_Classes]) #正解ラベル\n",
        "keep_prob = tf.placeholder('float')\n",
        "\n",
        "# -----------------------------------------\n",
        "# 畳み込みニューラルネットワーク\n",
        "#\n",
        "# (convconv -> bn -> pool -> drop) x3，\n",
        "# (fc->drop) x2\n",
        "# -----------------------------------------\n",
        "\n",
        "keep_prob = tf.placeholder('float')\n",
        "\n",
        "#第1ブロック\n",
        "W_conv1_1 = weight_variable([1,5,3,filterSize])\n",
        "b_conv1_1 = bias_variable([filterSize])\n",
        "x_image = tf.reshape(x,[-1,1,CaptureNumber,3])\n",
        "h_conv1_1 = conv2d(x_image, W_conv1_1)\n",
        "tan1_1 = Activation(h_conv1_1)\n",
        "bn1_1 = batch_normalization(filterSize,tan1_1)\n",
        "\n",
        "W_conv1_2 = weight_variable([1,5,filterSize,filterSize])\n",
        "b_conv1_2 = bias_variable([filterSize])\n",
        "h_conv1_2 = conv2d(bn1_1, W_conv1_2)\n",
        "tan1_2 = Activation(h_conv1_2)\n",
        "bn1_2 = batch_normalization(filterSize,tan1_2)\n",
        "\n",
        "h_pool1 = max_pool_2x2(bn1_2)\n",
        "h_pool1_drop = tf.nn.dropout(h_pool1, keep_prob)\n",
        "\n",
        "\n",
        "# #第2ブロック\n",
        "W_conv2_1 = weight_variable([1,5,filterSize,filterSize*2])\n",
        "b_conv2_1 = bias_variable([filterSize*2])\n",
        "h_conv2_1 = conv2d(h_pool1_drop, W_conv2_1)\n",
        "tan2_1 = Activation(h_conv2_1)\n",
        "bn2_1 = batch_normalization(filterSize*2,tan2_1)\n",
        "\n",
        "W_conv2_2 = weight_variable([1,5,filterSize*2,filterSize*2])\n",
        "b_conv2_2 = bias_variable([filterSize*2])\n",
        "h_conv2_2 = conv2d(bn2_1, W_conv2_2)\n",
        "tan2_2 = Activation(h_conv2_2)\n",
        "bn2_2 = batch_normalization(filterSize*2,tan2_2)\n",
        "\n",
        "h_pool2 = max_pool_2x2(bn2_2)\n",
        "h_pool2_drop = tf.nn.dropout(h_pool2, keep_prob)\n",
        "\n",
        "#\n",
        "\n",
        "# #第3ブロック\n",
        "W_conv3_1 = weight_variable([1,5,filterSize*2,filterSize*4])\n",
        "b_conv3_1 = bias_variable([filterSize*4])\n",
        "h_conv3_1 = conv2d(h_pool2_drop, W_conv3_1)\n",
        "tan3_1 = Activation(h_conv3_1)\n",
        "bn3_1 = batch_normalization(filterSize*4,tan3_1)\n",
        "\n",
        "W_conv3_2 = weight_variable([1,5,filterSize*4,filterSize*4])\n",
        "b_conv3_2 = bias_variable([filterSize*4])\n",
        "h_conv3_2 = conv2d(bn3_1, W_conv3_2)\n",
        "tan3_2 = Activation(h_conv3_2)\n",
        "bn3_2 = batch_normalization(filterSize*4,tan3_2)\n",
        "\n",
        "\n",
        "h_pool3 = max_pool_2x2(bn3_2)\n",
        "h_pool3_drop = tf.nn.dropout(h_pool3, keep_prob)\n",
        "h_pool3_flat = tf.reshape(h_pool3_drop, [-1,allCSize])\n",
        "\n",
        "#全結合層\n",
        "W_fc1 = weight_variable([allCSize, allCSize])\n",
        "b_fc1 = bias_variable([allCSize])\n",
        "h_fc1 = tf.nn.relu(tf.matmul(h_pool3_flat, W_fc1) + b_fc1)\n",
        "bn4 = batch_normalization(allCSize,h_fc1)\n",
        "\n",
        "# #dropout\n",
        "h_fc1_drop = tf.nn.dropout(bn4, 1.0)\n",
        "\n",
        "# #全結合層\n",
        "W_fc2 = weight_variable([allCSize, allCSize])\n",
        "b_fc2 = bias_variable([allCSize])\n",
        "\n",
        "h_fc2= tf.nn.relu(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
        "bn5 = batch_normalization(allCSize,h_fc1)\n",
        "\n",
        "# #dropout\n",
        "h_fc2_drop = tf.nn.dropout(bn5, 0.5)\n",
        "\n",
        "#softmaxで出力#\n",
        "W_fc4 = weight_variable([allCSize, Data_Classes])\n",
        "b_fc4 = bias_variable([Data_Classes])\n",
        "y_conv=tf.nn.softmax(tf.matmul(h_fc2_drop, W_fc4) + b_fc4)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#------------------\n",
        "# 評価と損失関数\n",
        "#------------------\n",
        "\n",
        "#L2ノルムを足そうとした残骸\n",
        "# L2_sqr = tf.nn.l2_loss(W_conv1) + tf.nn.l2_loss(W_conv2)+tf.nn.l2_loss(W_conv3) + tf.nn.l2_loss(W_fc1) + tf.nn.l2_loss(W_fc2)\n",
        "# lambda_2 = 0.01\n",
        "\n",
        "#クロスエントロピー誤差関数，1e-7を足して，勾配消失を防止\n",
        "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_*tf.log(y_conv+1e-7),reduction_indices=[1]))\n",
        "#loss = cross_entropy + lambda_2*L2_sqr\n",
        "# cross_entropy = -tf.reduce_sum(y_*tf.log(tf.clip_by_value(y_conv,1e-10,1.0)))\n",
        "\n",
        "#重みの最適化\n",
        "train_step = tf.train.AdamOptimizer(1e-3).minimize(cross_entropy)\n",
        "#　推定結果のy_convと正解ラベルy_が同じかどうか判定，correct_predictionがbool配列になってる\n",
        "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_,1))\n",
        "# 正答率\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "# run\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "\n",
        "\n",
        "#\n",
        "#学習器の保存処理\n",
        "saver = tf.train.Saver()\n",
        "ckpt = tf.train.get_checkpoint_state('./')\n",
        "cwd = os.getcwd()\n",
        "\n",
        "#モデルのロード\n",
        "# if ckpt:\n",
        "#      saver.restore(sess,cwd+\"\\\\model.ckpt\")\n",
        "# #\n",
        "\n",
        "#処理時間計測\n",
        "startTime = datetime.datetime.today()\n",
        "\n",
        "#ログ\n",
        "learn = open('log.csv','w')\n",
        "result = open('result.txt','w')\n",
        "\n",
        "\n",
        "#learn.write(\"学習ログ データ: %s クラス数:%d ステップ数:%d\\n\\n\"%(train_dir_name[0],Data_Classes,steps))\n",
        "learn.write(\"class,step\\n\" )\n",
        "learn.write(\"%g,%g\\n\"%(Data_Classes,steps))\n",
        "learn.write(\"step,train_a,test_a\\n\" )\n",
        "#result.write(\"結果，confusion matrix\\n\\n\")\n",
        "\n",
        "#学習ループ\n",
        "#配列に入れた加速度データから，ランダムにデータを選択，さらにそこから3x200に切り出して学習にかける\n",
        "for i in range(steps):\n",
        "\n",
        "    #加速度データの中からランダムにデータを選択\n",
        "    batch_mask = np.random.choice(len(train_data),BATCH_SIZE)\n",
        "    tbatch_mask = np.random.choice(len(test_data),BATCH_SIZE)\n",
        "\n",
        "    #バッチ配列\n",
        "    train_data_batch = []\n",
        "    train_label_batch = train_label[batch_mask]\n",
        "    test_data_batch = []\n",
        "\n",
        "    #3x200に切り出し_訓練データ\n",
        "    for g in batch_mask:\n",
        "        b_data = train_data[g]\n",
        "\n",
        "        b_x = b_data[0]\n",
        "        b_y = b_data[1]\n",
        "        b_z = b_data[2]\n",
        "\n",
        "        rdata = []\n",
        "        start = random.randint(0, len(b_x) - CaptureNumber)\n",
        "        end = start + CaptureNumber\n",
        "\n",
        "        x_data = b_x[start:end]\n",
        "        y_data = b_y[start:end]\n",
        "        z_data = b_z[start:end]\n",
        "\n",
        "        rdata.append(x_data)\n",
        "        rdata.append(y_data)\n",
        "        rdata.append(z_data)\n",
        "\n",
        "        train_data_batch.append(rdata)\n",
        "\n",
        "    # 3x200に切り出し_テストデータ\n",
        "    for g in range(len(test_data)):\n",
        "        b_data = test_data[g]\n",
        "\n",
        "        b_x = b_data[0]\n",
        "        b_y = b_data[1]\n",
        "        b_z = b_data[2]\n",
        "\n",
        "        rdata = []\n",
        "        start = random.randint(0, len(b_x) - CaptureNumber)\n",
        "        end = start + CaptureNumber\n",
        "\n",
        "        x_data = b_x[start:end]\n",
        "        y_data = b_y[start:end]\n",
        "        z_data = b_z[start:end]\n",
        "\n",
        "        rdata.append(x_data)\n",
        "        rdata.append(y_data)\n",
        "        rdata.append(z_data)\n",
        "\n",
        "        test_data_batch.append(rdata)\n",
        "\n",
        "\n",
        "    # 学習の実行　x＝データy＿＝ラベル keep_prob=dropoutでどれだけノード消すか\n",
        "    w_out, _ = sess.run([y_conv, train_step],feed_dict={x: train_data_batch, y_: train_label_batch, keep_prob:drop})\n",
        "\n",
        "    #精度の計算\n",
        "    train_accuracy = accuracy.eval(feed_dict={\n",
        "        x: train_data_batch, y_: train_label_batch, keep_prob:drop})\n",
        "\n",
        "    # 10ステップごとに精度を記録\n",
        "    if i % 10 == 0 :\n",
        "        test_accuracy = accuracy.eval(feed_dict={\n",
        "            x: test_data_batch, y_: test_label, keep_prob: drop})\n",
        "\n",
        "        print(\"step %d, training accuracy %g   test accuracy %g\" % (i, train_accuracy, test_accuracy))\n",
        "        learn.write(\"%d,%g,%g\\n\" % (i, train_accuracy, test_accuracy))\n",
        "\n",
        "    #終了一回前にいろいろ作成\n",
        "    if i == steps-1:\n",
        "\n",
        "        # confusion matrix 作成\n",
        "        y_p = tf.argmax(y_conv, 1)\n",
        "        val_accuracy, y_pred = sess.run([accuracy, y_p], feed_dict={x: test_data_batch, y_: test_label, keep_prob: drop})\n",
        "        y_true = np.argmax(test_label, 1)\n",
        "        con = confusion_matrix(y_true, y_pred)\n",
        "        print(con)\n",
        "\n",
        "        #検証データ分類用\n",
        "        #y_pred_1 = sess.run([y_p],feed_dict={x: Ex_TestDatas, keep_prob: drop})\n",
        "        # y_pred2 = y_pred_1[0]\n",
        "        # print(y_pred2)\n",
        "        # print(len(y_pred2))\n",
        "\n",
        "\n",
        "\n",
        "        print(\"ccn test 正答率 %g\" % accuracy.eval(feed_dict={\n",
        "            x: test_data_batch, y_: test_label, keep_prob: drop\n",
        "        }))\n",
        "\n",
        "#         print(\"ccn realtime test 正答率 %g\" % accuracy.eval(feed_dict={\n",
        "#             x: Ex_TestDatas, y_: Ex_Label, keep_prob: drop\n",
        "#         }))\n",
        "\n",
        "        #処理時間計測，終わり\n",
        "        endTime = datetime.datetime.today()\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"開始時刻 %s\" % (startTime))\n",
        "        print(\"終了時刻 %s\" % (endTime))\n",
        "\n",
        "        learn.write(\"\\n開始時刻 %s\\n\" % (startTime))\n",
        "        learn.write(\"終了時刻 %s\\n\" % (endTime))\n",
        "        learn.write(\"ccn test 正答率 %g\" % accuracy.eval(feed_dict={\n",
        "            x: test_data_batch, y_: test_label, keep_prob: drop\n",
        "        }))\n",
        "\n",
        "        #confusion matrixについて，精度を百分率表記したcon1と何が何回正解したかを表すconの両方つくる\n",
        "        con_sum = np.sum(con, axis=1)\n",
        "        con1 = []\n",
        "        for a in range(len(con)):\n",
        "            c = con[a] / con_sum[a]\n",
        "            con1.append(c)\n",
        "\n",
        "        print(con_sum)\n",
        "        print(con)\n",
        "        result.write(\"Confusion Matrix :\\n\")\n",
        "        # np.savetxt('result.txt',con,fmt=\"%0.2f\")\n",
        "        np.savetxt('confusion-no.csv', con, fmt=\"%0.3f\", delimiter=',')\n",
        "        np.savetxt('confusion.csv', con1, fmt=\"%0.3f\", delimiter=',')\n",
        "\n",
        "\n",
        "        ##学習器の保存処理２\n",
        "saver.save(sess,cwd+\"\\\\0model.ckpt\")\n",
        "\n",
        "\n",
        "\n",
        "learn.close()\n",
        "#result.close()\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "9\n",
            "train_folder_name\n",
            "['tcarpet1_241.csv', 'tcarpet1_29.csv', 'tcarpet1_255.csv', 'tcarpet1_269.csv', 'tcarpet1_282.csv', 'tcarpet1_296.csv', 'tcarpet1_254.csv', 'tcarpet1_240.csv', 'tcarpet1_297.csv', 'tcarpet1_283.csv', 'tcarpet1_256.csv', 'tcarpet1_268.csv', 'tcarpet1_243.csv', 'tcarpet1_257.csv', 'tcarpet1_295.csv', 'tcarpet1_28.csv', 'tcarpet1_281.csv', 'tcarpet1_242.csv', 'tcarpet1_246.csv', 'tcarpet1_294.csv', 'tcarpet1_280.csv', 'tcarpet1_290.csv', 'tcarpet1_285.csv', 'tcarpet1_252.csv', 'tcarpet1_253.csv', 'tcarpet1_247.csv', 'tcarpet1_284.csv', 'tcarpet1_293.csv', 'tcarpet1_287.csv', 'tcarpet1_291.csv', 'tcarpet1_250.csv', 'tcarpet1_278.csv', 'tcarpet1_244.csv', 'tcarpet1_251.csv', 'tcarpet1_245.csv', 'tcarpet1_292.csv', 'tcarpet1_222.csv', 'tcarpet1_279.csv', 'tcarpet1_286.csv', 'tcarpet1_236.csv', 'tcarpet1_237.csv', 'tcarpet1_223.csv', 'tcarpet1_221.csv', 'tcarpet1_230.csv', 'tcarpet1_234.csv', 'tcarpet1_235.csv', 'tcarpet1_218.csv', 'tcarpet1_220.csv', 'tcarpet1_231.csv', 'tcarpet1_224.csv', 'tcarpet1_219.csv', 'tcarpet1_225.csv', 'tcarpet1_232.csv', 'tcarpet1_233.csv', 'tcarpet1_226.csv', 'tcarpet1_227.csv', 'tcarpet1_217.csv', 'tcarpet1_2100.csv', 'tcarpet1_228.csv', 'tcarpet1_215.csv', 'tcarpet1_229.csv', 'tcarpet1_211.csv', 'tcarpet1_2101.csv', 'tcarpet1_216.csv', 'tcarpet1_2103.csv', 'tcarpet1_214.csv', 'tcarpet1_239.csv', 'tcarpet1_238.csv', 'tcarpet1_2102.csv', 'tcarpet1_212.csv', 'tcarpet1_213.csv', 'tcarpet1_210.csv', 'tcarpet1_260.csv', 'tcarpet1_275.csv', 'tcarpet1_261.csv', 'tcarpet1_21.csv', 'tcarpet1_274.csv', 'tcarpet1_288.csv', 'tcarpet1_2104.csv', 'tcarpet1_20.csv', 'tcarpet1_248.csv', 'tcarpet1_23.csv', 'tcarpet1_249.csv', 'tcarpet1_277.csv', 'tcarpet1_262.csv', 'tcarpet1_276.csv', 'tcarpet1_22.csv', 'tcarpet1_26.csv', 'tcarpet1_267.csv', 'tcarpet1_273.csv', 'tcarpet1_263.csv', 'tcarpet1_289.csv', 'tcarpet1_299.csv', 'tcarpet1_272.csv', 'tcarpet1_266.csv', 'tcarpet1_298.csv', 'tcarpet1_27.csv', 'tcarpet1_259.csv', 'tcarpet1_270.csv', 'tcarpet1_25.csv', 'tcarpet1_265.csv', 'tcarpet1_271.csv', 'tcarpet1_24.csv', 'tcarpet1_258.csv', 'tcarpet1_264.csv']\n",
            "['twoodtile1_28.csv', 'twoodtile1_215.csv', 'twoodtile1_214.csv', 'twoodtile1_229.csv', 'twoodtile1_228.csv', 'twoodtile1_216.csv', 'twoodtile1_29.csv', 'twoodtile1_217.csv', 'twoodtile1_213.csv', 'twoodtile1_262.csv', 'twoodtile1_239.csv', 'twoodtile1_289.csv', 'twoodtile1_211.csv', 'twoodtile1_210.csv', 'twoodtile1_238.csv', 'twoodtile1_212.csv', 'twoodtile1_288.csv', 'twoodtile1_276.csv', 'twoodtile1_277.csv', 'twoodtile1_260.csv', 'twoodtile1_263.csv', 'twoodtile1_274.csv', 'twoodtile1_270.csv', 'twoodtile1_258.csv', 'twoodtile1_261.csv', 'twoodtile1_249.csv', 'twoodtile1_275.csv', 'twoodtile1_248.csv', 'twoodtile1_264.csv', 'twoodtile1_273.csv', 'twoodtile1_265.csv', 'twoodtile1_266.csv', 'twoodtile1_271.csv', 'twoodtile1_259.csv', 'twoodtile1_272.csv', 'twoodtile1_298.csv', 'twoodtile1_299.csv', 'twoodtile1_267.csv', 'twoodtile1_243.csv', 'twoodtile1_257.csv', 'twoodtile1_280.csv', 'twoodtile1_294.csv', 'twoodtile1_281.csv', 'twoodtile1_295.csv', 'twoodtile1_254.csv', 'twoodtile1_240.csv', 'twoodtile1_283.csv', 'twoodtile1_282.csv', 'twoodtile1_241.csv', 'twoodtile1_242.csv', 'twoodtile1_256.csv', 'twoodtile1_268.csv', 'twoodtile1_255.csv', 'twoodtile1_297.csv', 'twoodtile1_269.csv', 'twoodtile1_292.csv', 'twoodtile1_296.csv', 'twoodtile1_251.csv', 'twoodtile1_279.csv', 'twoodtile1_245.csv', 'twoodtile1_286.csv', 'twoodtile1_287.csv', 'twoodtile1_278.csv', 'twoodtile1_244.csv', 'twoodtile1_246.csv', 'twoodtile1_250.csv', 'twoodtile1_290.csv', 'twoodtile1_293.csv', 'twoodtile1_285.csv', 'twoodtile1_291.csv', 'twoodtile1_252.csv', 'twoodtile1_284.csv', 'twoodtile1_220.csv', 'twoodtile1_247.csv', 'twoodtile1_234.csv', 'twoodtile1_20.csv', 'twoodtile1_221.csv', 'twoodtile1_21.csv', 'twoodtile1_253.csv', 'twoodtile1_22.csv', 'twoodtile1_235.csv', 'twoodtile1_237.csv', 'twoodtile1_223.csv', 'twoodtile1_23.csv', 'twoodtile1_222.csv', 'twoodtile1_232.csv', 'twoodtile1_227.csv', 'twoodtile1_225.csv', 'twoodtile1_26.csv', 'twoodtile1_27.csv', 'twoodtile1_226.csv', 'twoodtile1_231.csv', 'twoodtile1_236.csv', 'twoodtile1_219.csv', 'twoodtile1_233.csv', 'twoodtile1_24.csv', 'twoodtile1_224.csv', 'twoodtile1_25.csv', 'twoodtile1_230.csv', 'twoodtile1_218.csv']\n",
            "['tcarpet2_235.csv', 'tcarpet2_236.csv', 'tcarpet2_237.csv', 'tcarpet2_221.csv', 'tcarpet2_234.csv', 'tcarpet2_220.csv', 'tcarpet2_227.csv', 'tcarpet2_223.csv', 'tcarpet2_222.csv', 'tcarpet2_232.csv', 'tcarpet2_233.csv', 'tcarpet2_226.csv', 'tcarpet2_224.csv', 'tcarpet2_225.csv', 'tcarpet2_27.csv', 'tcarpet2_295.csv', 'tcarpet2_256.csv', 'tcarpet2_230.csv', 'tcarpet2_218.csv', 'tcarpet2_219.csv', 'tcarpet2_231.csv', 'tcarpet2_281.csv', 'tcarpet2_242.csv', 'tcarpet2_280.csv', 'tcarpet2_243.csv', 'tcarpet2_257.csv', 'tcarpet2_24.csv', 'tcarpet2_26.csv', 'tcarpet2_282.csv', 'tcarpet2_294.csv', 'tcarpet2_296.csv', 'tcarpet2_255.csv', 'tcarpet2_241.csv', 'tcarpet2_269.csv', 'tcarpet2_297.csv', 'tcarpet2_283.csv', 'tcarpet2_240.csv', 'tcarpet2_268.csv', 'tcarpet2_254.csv', 'tcarpet2_21.csv', 'tcarpet2_244.csv', 'tcarpet2_25.csv', 'tcarpet2_293.csv', 'tcarpet2_278.csv', 'tcarpet2_250.csv', 'tcarpet2_287.csv', 'tcarpet2_292.csv', 'tcarpet2_286.csv', 'tcarpet2_251.csv', 'tcarpet2_20.csv', 'tcarpet2_279.csv', 'tcarpet2_245.csv', 'tcarpet2_22.csv', 'tcarpet2_253.csv', 'tcarpet2_285.csv', 'tcarpet2_291.csv', 'tcarpet2_252.csv', 'tcarpet2_277.csv', 'tcarpet2_290.csv', 'tcarpet2_284.csv', 'tcarpet2_247.csv', 'tcarpet2_246.csv', 'tcarpet2_263.csv', 'tcarpet2_288.csv', 'tcarpet2_23.csv', 'tcarpet2_289.csv', 'tcarpet2_262.csv', 'tcarpet2_248.csv', 'tcarpet2_260.csv', 'tcarpet2_276.csv', 'tcarpet2_249.csv', 'tcarpet2_28.csv', 'tcarpet2_271.csv', 'tcarpet2_274.csv', 'tcarpet2_275.csv', 'tcarpet2_259.csv', 'tcarpet2_265.csv', 'tcarpet2_258.csv', 'tcarpet2_264.csv', 'tcarpet2_270.csv', 'tcarpet2_29.csv', 'tcarpet2_261.csv', 'tcarpet2_266.csv', 'tcarpet2_272.csv', 'tcarpet2_267.csv', 'tcarpet2_228.csv', 'tcarpet2_229.csv', 'tcarpet2_217.csv', 'tcarpet2_298.csv', 'tcarpet2_212.csv', 'tcarpet2_214.csv', 'tcarpet2_215.csv', 'tcarpet2_273.csv', 'tcarpet2_213.csv', 'tcarpet2_216.csv', 'tcarpet2_211.csv', 'tcarpet2_238.csv', 'tcarpet2_239.csv', 'tcarpet2_210.csv']\n",
            "['tsponge-y_293.csv', 'tsponge-y_278.csv', 'tsponge-y_250.csv', 'tsponge-y_20.csv', 'tsponge-y_287.csv', 'tsponge-y_244.csv', 'tsponge-y_279.csv', 'tsponge-y_251.csv', 'tsponge-y_21.csv', 'tsponge-y_292.csv', 'tsponge-y_245.csv', 'tsponge-y_284.csv', 'tsponge-y_286.csv', 'tsponge-y_247.csv', 'tsponge-y_22.csv', 'tsponge-y_23.csv', 'tsponge-y_253.csv', 'tsponge-y_290.csv', 'tsponge-y_291.csv', 'tsponge-y_295.csv', 'tsponge-y_285.csv', 'tsponge-y_252.csv', 'tsponge-y_246.csv', 'tsponge-y_256.csv', 'tsponge-y_27.csv', 'tsponge-y_26.csv', 'tsponge-y_243.csv', 'tsponge-y_257.csv', 'tsponge-y_242.csv', 'tsponge-y_241.csv', 'tsponge-y_296.csv', 'tsponge-y_281.csv', 'tsponge-y_294.csv', 'tsponge-y_280.csv', 'tsponge-y_282.csv', 'tsponge-y_255.csv', 'tsponge-y_24.csv', 'tsponge-y_25.csv', 'tsponge-y_254.csv', 'tsponge-y_240.csv', 'tsponge-y_268.csv', 'tsponge-y_269.csv', 'tsponge-y_233.csv', 'tsponge-y_232.csv', 'tsponge-y_218.csv', 'tsponge-y_297.csv', 'tsponge-y_283.csv', 'tsponge-y_227.csv', 'tsponge-y_226.csv', 'tsponge-y_230.csv', 'tsponge-y_225.csv', 'tsponge-y_231.csv', 'tsponge-y_219.csv', 'tsponge-y_224.csv', 'tsponge-y_234.csv', 'tsponge-y_222.csv', 'tsponge-y_237.csv', 'tsponge-y_212.csv', 'tsponge-y_236.csv', 'tsponge-y_213.csv', 'tsponge-y_221.csv', 'tsponge-y_220.csv', 'tsponge-y_235.csv', 'tsponge-y_239.csv', 'tsponge-y_223.csv', 'tsponge-y_211.csv', 'tsponge-y_210.csv', 'tsponge-y_229.csv', 'tsponge-y_238.csv', 'tsponge-y_259.csv', 'tsponge-y_265.csv', 'tsponge-y_271.csv', 'tsponge-y_217.csv', 'tsponge-y_215.csv', 'tsponge-y_228.csv', 'tsponge-y_216.csv', 'tsponge-y_214.csv', 'tsponge-y_28.csv', 'tsponge-y_264.csv', 'tsponge-y_29.csv', 'tsponge-y_258.csv', 'tsponge-y_273.csv', 'tsponge-y_288.csv', 'tsponge-y_267.csv', 'tsponge-y_272.csv', 'tsponge-y_266.csv', 'tsponge-y_270.csv', 'tsponge-y_277.csv', 'tsponge-y_298.csv', 'tsponge-y_263.csv', 'tsponge-y_276.csv', 'tsponge-y_289.csv', 'tsponge-y_262.csv', 'tsponge-y_260.csv', 'tsponge-y_248.csv', 'tsponge-y_261.csv', 'tsponge-y_275.csv', 'tsponge-y_249.csv', 'tsponge-y_274.csv']\n",
            "['tsponge-g_236.csv', 'tsponge-g_223.csv', 'tsponge-g_222.csv', 'tsponge-g_221.csv', 'tsponge-g_237.csv', 'tsponge-g_235.csv', 'tsponge-g_234.csv', 'tsponge-g_220.csv', 'tsponge-g_224.csv', 'tsponge-g_219.csv', 'tsponge-g_218.csv', 'tsponge-g_233.csv', 'tsponge-g_227.csv', 'tsponge-g_225.csv', 'tsponge-g_230.csv', 'tsponge-g_231.csv', 'tsponge-g_226.csv', 'tsponge-g_296.csv', 'tsponge-g_22.csv', 'tsponge-g_282.csv', 'tsponge-g_255.csv', 'tsponge-g_232.csv', 'tsponge-g_268.csv', 'tsponge-g_269.csv', 'tsponge-g_297.csv', 'tsponge-g_241.csv', 'tsponge-g_254.csv', 'tsponge-g_240.csv', 'tsponge-g_23.csv', 'tsponge-g_21.csv', 'tsponge-g_295.csv', 'tsponge-g_242.csv', 'tsponge-g_283.csv', 'tsponge-g_256.csv', 'tsponge-g_281.csv', 'tsponge-g_243.csv', 'tsponge-g_294.csv', 'tsponge-g_284.csv', 'tsponge-g_290.csv', 'tsponge-g_253.csv', 'tsponge-g_24.csv', 'tsponge-g_280.csv', 'tsponge-g_20.csv', 'tsponge-g_257.csv', 'tsponge-g_252.csv', 'tsponge-g_247.csv', 'tsponge-g_246.csv', 'tsponge-g_291.csv', 'tsponge-g_293.csv', 'tsponge-g_287.csv', 'tsponge-g_250.csv', 'tsponge-g_244.csv', 'tsponge-g_245.csv', 'tsponge-g_25.csv', 'tsponge-g_285.csv', 'tsponge-g_27.csv', 'tsponge-g_278.csv', 'tsponge-g_279.csv', 'tsponge-g_292.csv', 'tsponge-g_286.csv', 'tsponge-g_251.csv', 'tsponge-g_274.csv', 'tsponge-g_248.csv', 'tsponge-g_275.csv', 'tsponge-g_26.csv', 'tsponge-g_28.csv', 'tsponge-g_263.csv', 'tsponge-g_277.csv', 'tsponge-g_288.csv', 'tsponge-g_249.csv', 'tsponge-g_260.csv', 'tsponge-g_261.csv', 'tsponge-g_262.csv', 'tsponge-g_289.csv', 'tsponge-g_29.csv', 'tsponge-g_299.csv', 'tsponge-g_276.csv', 'tsponge-g_272.csv', 'tsponge-g_259.csv', 'tsponge-g_271.csv', 'tsponge-g_298.csv', 'tsponge-g_267.csv', 'tsponge-g_273.csv', 'tsponge-g_266.csv', 'tsponge-g_265.csv', 'tsponge-g_270.csv', 'tsponge-g_217.csv', 'tsponge-g_216.csv', 'tsponge-g_228.csv', 'tsponge-g_264.csv', 'tsponge-g_258.csv', 'tsponge-g_2101.csv', 'tsponge-g_239.csv', 'tsponge-g_215.csv', 'tsponge-g_214.csv', 'tsponge-g_229.csv', 'tsponge-g_211.csv', 'tsponge-g_238.csv', 'tsponge-g_210.csv', 'tsponge-g_213.csv', 'tsponge-g_212.csv', 'tsponge-g_2100.csv']\n",
            "['twhitetile1_228.csv', 'twhitetile1_214.csv', 'twhitetile1_229.csv', 'twhitetile1_217.csv', 'twhitetile1_216.csv', 'twhitetile1_213.csv', 'twhitetile1_215.csv', 'twhitetile1_212.csv', 'twhitetile1_239.csv', 'twhitetile1_28.csv', 'twhitetile1_288.csv', 'twhitetile1_277.csv', 'twhitetile1_210.csv', 'twhitetile1_238.csv', 'twhitetile1_211.csv', 'twhitetile1_262.csv', 'twhitetile1_276.csv', 'twhitetile1_289.csv', 'twhitetile1_263.csv', 'twhitetile1_248.csv', 'twhitetile1_29.csv', 'twhitetile1_275.csv', 'twhitetile1_249.csv', 'twhitetile1_265.csv', 'twhitetile1_274.csv', 'twhitetile1_261.csv', 'twhitetile1_260.csv', 'twhitetile1_259.csv', 'twhitetile1_258.csv', 'twhitetile1_264.csv', 'twhitetile1_266.csv', 'twhitetile1_271.csv', 'twhitetile1_270.csv', 'twhitetile1_272.csv', 'twhitetile1_281.csv', 'twhitetile1_295.csv', 'twhitetile1_256.csv', 'twhitetile1_242.csv', 'twhitetile1_267.csv', 'twhitetile1_273.csv', 'twhitetile1_21.csv', 'twhitetile1_257.csv', 'twhitetile1_294.csv', 'twhitetile1_280.csv', 'twhitetile1_20.csv', 'twhitetile1_243.csv', 'twhitetile1_296.csv', 'twhitetile1_282.csv', 'twhitetile1_269.csv', 'twhitetile1_254.csv', 'twhitetile1_22.csv', 'twhitetile1_268.csv', 'twhitetile1_283.csv', 'twhitetile1_255.csv', 'twhitetile1_241.csv', 'twhitetile1_240.csv', 'twhitetile1_27.csv', 'twhitetile1_287.csv', 'twhitetile1_293.csv', 'twhitetile1_250.csv', 'twhitetile1_23.csv', 'twhitetile1_244.csv', 'twhitetile1_251.csv', 'twhitetile1_245.csv', 'twhitetile1_279.csv', 'twhitetile1_278.csv', 'twhitetile1_286.csv', 'twhitetile1_292.csv', 'twhitetile1_284.csv', 'twhitetile1_26.csv', 'twhitetile1_290.csv', 'twhitetile1_24.csv', 'twhitetile1_247.csv', 'twhitetile1_253.csv', 'twhitetile1_291.csv', 'twhitetile1_221.csv', 'twhitetile1_220.csv', 'twhitetile1_234.csv', 'twhitetile1_252.csv', 'twhitetile1_25.csv', 'twhitetile1_246.csv', 'twhitetile1_285.csv', 'twhitetile1_236.csv', 'twhitetile1_235.csv', 'twhitetile1_222.csv', 'twhitetile1_223.csv', 'twhitetile1_232.csv', 'twhitetile1_224.csv', 'twhitetile1_237.csv', 'twhitetile1_227.csv', 'twhitetile1_233.csv', 'twhitetile1_218.csv', 'twhitetile1_219.csv', 'twhitetile1_226.csv', 'twhitetile1_231.csv', 'twhitetile1_230.csv', 'twhitetile1_225.csv']\n",
            "['tcarpet3_218.csv', 'tcarpet3_231.csv', 'tcarpet3_219.csv', 'tcarpet3_224.csv', 'tcarpet3_230.csv', 'tcarpet3_225.csv', 'tcarpet3_233.csv', 'tcarpet3_226.csv', 'tcarpet3_232.csv', 'tcarpet3_236.csv', 'tcarpet3_227.csv', 'tcarpet3_2100.csv', 'tcarpet3_223.csv', 'tcarpet3_222.csv', 'tcarpet3_237.csv', 'tcarpet3_29.csv', 'tcarpet3_235.csv', 'tcarpet3_234.csv', 'tcarpet3_220.csv', 'tcarpet3_290.csv', 'tcarpet3_247.csv', 'tcarpet3_221.csv', 'tcarpet3_291.csv', 'tcarpet3_284.csv', 'tcarpet3_253.csv', 'tcarpet3_28.csv', 'tcarpet3_285.csv', 'tcarpet3_246.csv', 'tcarpet3_278.csv', 'tcarpet3_250.csv', 'tcarpet3_252.csv', 'tcarpet3_293.csv', 'tcarpet3_244.csv', 'tcarpet3_286.csv', 'tcarpet3_279.csv', 'tcarpet3_269.csv', 'tcarpet3_251.csv', 'tcarpet3_241.csv', 'tcarpet3_255.csv', 'tcarpet3_296.csv', 'tcarpet3_287.csv', 'tcarpet3_245.csv', 'tcarpet3_292.csv', 'tcarpet3_282.csv', 'tcarpet3_283.csv', 'tcarpet3_268.csv', 'tcarpet3_254.csv', 'tcarpet3_297.csv', 'tcarpet3_240.csv', 'tcarpet3_256.csv', 'tcarpet3_295.csv', 'tcarpet3_242.csv', 'tcarpet3_257.csv', 'tcarpet3_266.csv', 'tcarpet3_243.csv', 'tcarpet3_281.csv', 'tcarpet3_280.csv', 'tcarpet3_294.csv', 'tcarpet3_299.csv', 'tcarpet3_272.csv', 'tcarpet3_298.csv', 'tcarpet3_273.csv', 'tcarpet3_271.csv', 'tcarpet3_270.csv', 'tcarpet3_258.csv', 'tcarpet3_260.csv', 'tcarpet3_265.csv', 'tcarpet3_259.csv', 'tcarpet3_264.csv', 'tcarpet3_248.csv', 'tcarpet3_267.csv', 'tcarpet3_274.csv', 'tcarpet3_261.csv', 'tcarpet3_288.csv', 'tcarpet3_249.csv', 'tcarpet3_276.csv', 'tcarpet3_263.csv', 'tcarpet3_275.csv', 'tcarpet3_277.csv', 'tcarpet3_262.csv', 'tcarpet3_25.csv', 'tcarpet3_289.csv', 'tcarpet3_239.csv', 'tcarpet3_210.csv', 'tcarpet3_238.csv', 'tcarpet3_211.csv', 'tcarpet3_26.csv', 'tcarpet3_27.csv', 'tcarpet3_23.csv', 'tcarpet3_24.csv', 'tcarpet3_212.csv', 'tcarpet3_213.csv', 'tcarpet3_216.csv', 'tcarpet3_22.csv', 'tcarpet3_20.csv', 'tcarpet3_214.csv', 'tcarpet3_217.csv', 'tcarpet3_229.csv', 'tcarpet3_228.csv', 'tcarpet3_21.csv', 'tcarpet3_215.csv']\n",
            "['tstonetile1_29.csv', 'tstonetile1_236.csv', 'tstonetile1_220.csv', 'tstonetile1_223.csv', 'tstonetile1_237.csv', 'tstonetile1_235.csv', 'tstonetile1_234.csv', 'tstonetile1_222.csv', 'tstonetile1_28.csv', 'tstonetile1_231.csv', 'tstonetile1_221.csv', 'tstonetile1_219.csv', 'tstonetile1_230.csv', 'tstonetile1_232.csv', 'tstonetile1_225.csv', 'tstonetile1_218.csv', 'tstonetile1_224.csv', 'tstonetile1_233.csv', 'tstonetile1_268.csv', 'tstonetile1_240.csv', 'tstonetile1_226.csv', 'tstonetile1_283.csv', 'tstonetile1_227.csv', 'tstonetile1_282.csv', 'tstonetile1_241.csv', 'tstonetile1_257.csv', 'tstonetile1_243.csv', 'tstonetile1_255.csv', 'tstonetile1_269.csv', 'tstonetile1_296.csv', 'tstonetile1_297.csv', 'tstonetile1_254.csv', 'tstonetile1_294.csv', 'tstonetile1_242.csv', 'tstonetile1_281.csv', 'tstonetile1_280.csv', 'tstonetile1_246.csv', 'tstonetile1_295.csv', 'tstonetile1_256.csv', 'tstonetile1_252.csv', 'tstonetile1_285.csv', 'tstonetile1_291.csv', 'tstonetile1_284.csv', 'tstonetile1_290.csv', 'tstonetile1_253.csv', 'tstonetile1_245.csv', 'tstonetile1_279.csv', 'tstonetile1_251.csv', 'tstonetile1_286.csv', 'tstonetile1_293.csv', 'tstonetile1_247.csv', 'tstonetile1_250.csv', 'tstonetile1_278.csv', 'tstonetile1_292.csv', 'tstonetile1_287.csv', 'tstonetile1_261.csv', 'tstonetile1_244.csv', 'tstonetile1_275.csv', 'tstonetile1_274.csv', 'tstonetile1_248.csv', 'tstonetile1_260.csv', 'tstonetile1_289.csv', 'tstonetile1_276.csv', 'tstonetile1_249.csv', 'tstonetile1_267.csv', 'tstonetile1_288.csv', 'tstonetile1_263.csv', 'tstonetile1_262.csv', 'tstonetile1_277.csv', 'tstonetile1_272.csv', 'tstonetile1_266.csv', 'tstonetile1_273.csv', 'tstonetile1_264.csv', 'tstonetile1_298.csv', 'tstonetile1_270.csv', 'tstonetile1_258.csv', 'tstonetile1_20.csv', 'tstonetile1_216.csv', 'tstonetile1_265.csv', 'tstonetile1_259.csv', 'tstonetile1_271.csv', 'tstonetile1_217.csv', 'tstonetile1_21.csv', 'tstonetile1_229.csv', 'tstonetile1_23.csv', 'tstonetile1_238.csv', 'tstonetile1_26.csv', 'tstonetile1_215.csv', 'tstonetile1_22.csv', 'tstonetile1_239.csv', 'tstonetile1_211.csv', 'tstonetile1_27.csv', 'tstonetile1_228.csv', 'tstonetile1_210.csv', 'tstonetile1_214.csv', 'tstonetile1_25.csv', 'tstonetile1_213.csv', 'tstonetile1_212.csv', 'tstonetile1_24.csv']\n",
            "ds_storeを抹殺\n",
            "[131 600 550 217  91 242 296 196 388  13 585 797 683  74  51 653 716 133\n",
            " 779 383 749 587 315  60 380 497 460 313 151 220  81  92 726 455 293  41\n",
            " 361 538 759 660 237 186  99 233 617 208 646 381 222 431  19 736 218 662\n",
            " 545 693 224  97 373 443  39 549 637 789  17 415  49 272 757 471 370  40\n",
            " 275 639 135 783 402 346 722 401 250 570 199  56 701 335 193  50 153 195\n",
            " 144 121 295 673  11 141 760 689 657 413 277 559 725 498 476 365 485 528\n",
            " 225  85  84 741  32 761 464  45 322 687 656 394  52 446 343 219 404  43\n",
            " 113 546 174 565 245  86 630 171 557 504 111 649 780 215 750 521  16 602\n",
            " 558 492 289  96   8 642 730 796  68 316 495 532 169 360 205 426  82 615\n",
            " 633  79 685 254 281  12 677 513 763 392 595 279  47 756 317 239 432 400\n",
            " 419 794 672 799 238  22 137 702 369 774 522 436   1 334 427   0 283  37\n",
            " 311 182  65 132 411 740 732 619  70 188  30 671 330 606 755 209  18 321\n",
            " 260 591 697 241  73 692 230 785 540 708 655 597 482  58 517 438 371 599\n",
            " 149 214  15  94 773 511 393 449 494   5 469 263 428 572 691 700 793 467\n",
            " 525 762 459 578 588 782  46 547 695 325 267 535 124 216 775 364 710 682\n",
            " 154 323 625 539 743 457 801 632 765 307 584 292 581 552 300 728 518 684\n",
            "  44  63 729 786 112 575  55 571  27 248 139 396 544 566 407 128 172 348\n",
            " 663 686 162 103 501 769 778 678  57 596 530 680 453 127   2 787 161 767\n",
            " 102 110 101 509 339 666  48 130 452  80 372 742 592 487  54 661 593 341\n",
            " 508 458 529 734 405 713 226 636 223  10  66 298 291 479 276 733 696 679\n",
            " 374 269 758  33 690 123 122 197 416 598 268 354 390 146 192 201  72 353\n",
            " 706 777 332 483 156 145 688 520 605 626 635 118 231 753 352  28 768 551\n",
            " 157 106 351 568 543 376 312 107 752 164 441 240 117 707 170 641 556 640\n",
            " 784 109 527 624  34 623 270 290 424 744 638 412 579 526  95 440 451 210\n",
            " 709 608  89 766 324 301 435 454 375 177 378 475  36 567 507 190  31 138\n",
            " 531 329 607 668 648 746 667  38 621 410 262 328 614 422 302 705 723 391\n",
            " 299 791 644 202 698 104 163 676 140 731 382 613 478 280 770 399 108 664\n",
            " 739 537 274 357  23 583 515 628 282 331 745 344 389  75 340   3 308 447\n",
            " 246 345 258 658 524 255 359 717  20  14 503  29 737 534 284 490 115  42\n",
            " 439 285 541 631 795 247 764 790 148 629 273 212 243 264 627 134 506 714\n",
            " 349 721 367 514 647 142 450 425 472 523 423 184 160  21 204 576 491 408\n",
            " 253 792 437  25 724 180 493 719 712 305 582 271 116 251 379 179  87 461\n",
            " 665 362 387 417 278 430 610 158 261 347 715 320 798 409 603 776 620 445\n",
            " 168 385 366 748 711 386 480  93  24 652 533 356 516 670 181 155 288 694\n",
            " 536 604 406 297 213  26 207 643 167 342 542  61 309 675 772 333 150 420\n",
            " 165 377 355 754 433 484 266 611 206 470 414 500 703 384 569 287 616 265\n",
            " 232 645 486 244 175  77  67 397 674 114 681 183 314 294 553 429   7 286\n",
            " 659 358  53 304 318  59 548 747 191 303 257 363 560 143   6 609 319  69\n",
            "  83 800 176 561 590 444 738 136 421 194 456 468 704 227 634 368 448 327\n",
            " 512 125 781 119 338 473 200 228 505 618 735 326 462 488 519 699  76 481\n",
            " 147 398 496 129 463  78 126 236 256 159 563 442 189 502 654 198 718 336\n",
            " 187 337 466 580 235 105  98 178 203 477 499 152 173 562 573 586 229 306\n",
            " 211 720 489 574 350 622 788  64 751  90 221 564 669 474 120 395  62 589\n",
            " 166 249 185 100 612 434 650 594 554  35 418 577 259 465 651   4   9 234\n",
            " 771 601 510  71 252 403  88 310 555 727]\n",
            "721\n",
            "80\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
            "  warnings.warn('An interactive session is already active. This can '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 0, training accuracy 0.611   test accuracy 0.525\n",
            "step 10, training accuracy 0.97   test accuracy 0.8625\n",
            "step 20, training accuracy 0.983   test accuracy 0.7\n",
            "step 30, training accuracy 0.978   test accuracy 0.75\n",
            "step 40, training accuracy 0.984   test accuracy 0.8\n",
            "step 50, training accuracy 0.985   test accuracy 0.875\n",
            "step 60, training accuracy 0.977   test accuracy 0.8875\n",
            "step 70, training accuracy 0.963   test accuracy 0.8625\n",
            "step 80, training accuracy 0.975   test accuracy 0.9125\n",
            "step 90, training accuracy 0.955   test accuracy 0.8375\n",
            "step 100, training accuracy 0.976   test accuracy 0.875\n",
            "step 110, training accuracy 0.984   test accuracy 0.8375\n",
            "step 120, training accuracy 0.978   test accuracy 0.8375\n",
            "step 130, training accuracy 0.985   test accuracy 0.7875\n",
            "step 140, training accuracy 0.991   test accuracy 0.825\n",
            "step 150, training accuracy 0.991   test accuracy 0.8125\n",
            "step 160, training accuracy 0.982   test accuracy 0.9125\n",
            "step 170, training accuracy 0.996   test accuracy 0.775\n",
            "step 180, training accuracy 0.971   test accuracy 0.8625\n",
            "step 190, training accuracy 0.995   test accuracy 0.85\n",
            "step 200, training accuracy 0.986   test accuracy 0.8125\n",
            "step 210, training accuracy 0.997   test accuracy 0.7875\n",
            "step 220, training accuracy 0.971   test accuracy 0.7375\n",
            "step 230, training accuracy 0.991   test accuracy 0.875\n",
            "step 240, training accuracy 0.998   test accuracy 0.8\n",
            "step 250, training accuracy 0.984   test accuracy 0.775\n",
            "step 260, training accuracy 0.995   test accuracy 0.825\n",
            "step 270, training accuracy 0.99   test accuracy 0.85\n",
            "step 280, training accuracy 0.995   test accuracy 0.8875\n",
            "step 290, training accuracy 0.946   test accuracy 0.95\n",
            "step 300, training accuracy 0.977   test accuracy 0.8625\n",
            "step 310, training accuracy 0.967   test accuracy 0.7625\n",
            "step 320, training accuracy 0.988   test accuracy 0.8875\n",
            "step 330, training accuracy 0.994   test accuracy 0.875\n",
            "step 340, training accuracy 0.989   test accuracy 0.8\n",
            "step 350, training accuracy 0.985   test accuracy 0.8875\n",
            "step 360, training accuracy 0.996   test accuracy 0.9\n",
            "step 370, training accuracy 0.999   test accuracy 0.8\n",
            "step 380, training accuracy 0.993   test accuracy 0.85\n",
            "step 390, training accuracy 0.986   test accuracy 0.8\n",
            "step 400, training accuracy 0.997   test accuracy 0.85\n",
            "step 410, training accuracy 0.993   test accuracy 0.8\n",
            "step 420, training accuracy 0.997   test accuracy 0.8625\n",
            "step 430, training accuracy 0.992   test accuracy 0.9\n",
            "step 440, training accuracy 0.999   test accuracy 0.7875\n",
            "step 450, training accuracy 1   test accuracy 0.8625\n",
            "step 460, training accuracy 0.992   test accuracy 0.85\n",
            "step 470, training accuracy 0.995   test accuracy 0.8\n",
            "step 480, training accuracy 0.989   test accuracy 0.9\n",
            "step 490, training accuracy 0.998   test accuracy 0.8375\n",
            "step 500, training accuracy 0.994   test accuracy 0.8125\n",
            "step 510, training accuracy 0.99   test accuracy 0.8875\n",
            "step 520, training accuracy 0.996   test accuracy 0.8375\n",
            "step 530, training accuracy 0.991   test accuracy 0.875\n",
            "step 540, training accuracy 0.992   test accuracy 0.9375\n",
            "step 550, training accuracy 0.992   test accuracy 0.9\n",
            "step 560, training accuracy 0.997   test accuracy 0.8875\n",
            "step 570, training accuracy 0.996   test accuracy 0.775\n",
            "step 580, training accuracy 0.995   test accuracy 0.825\n",
            "step 590, training accuracy 0.995   test accuracy 0.8875\n",
            "step 600, training accuracy 0.999   test accuracy 0.875\n",
            "step 610, training accuracy 0.997   test accuracy 0.85\n",
            "step 620, training accuracy 0.991   test accuracy 0.8125\n",
            "step 630, training accuracy 0.995   test accuracy 0.8375\n",
            "step 640, training accuracy 0.992   test accuracy 0.8375\n",
            "step 650, training accuracy 0.995   test accuracy 0.8\n",
            "step 660, training accuracy 0.988   test accuracy 0.9375\n",
            "step 670, training accuracy 0.986   test accuracy 0.8\n",
            "step 680, training accuracy 0.994   test accuracy 0.825\n",
            "step 690, training accuracy 0.995   test accuracy 0.8375\n",
            "step 700, training accuracy 0.999   test accuracy 0.95\n",
            "step 710, training accuracy 0.999   test accuracy 0.85\n",
            "step 720, training accuracy 0.999   test accuracy 0.8875\n",
            "step 730, training accuracy 0.997   test accuracy 0.8\n",
            "step 740, training accuracy 0.995   test accuracy 0.9125\n",
            "step 750, training accuracy 0.999   test accuracy 0.8625\n",
            "step 760, training accuracy 0.997   test accuracy 0.95\n",
            "step 770, training accuracy 0.993   test accuracy 0.85\n",
            "step 780, training accuracy 0.999   test accuracy 0.8875\n",
            "step 790, training accuracy 1   test accuracy 0.925\n",
            "step 800, training accuracy 0.989   test accuracy 0.9\n",
            "step 810, training accuracy 0.996   test accuracy 0.8625\n",
            "step 820, training accuracy 0.998   test accuracy 0.9125\n",
            "step 830, training accuracy 0.997   test accuracy 0.825\n",
            "step 840, training accuracy 1   test accuracy 0.8125\n",
            "step 850, training accuracy 0.992   test accuracy 0.925\n",
            "step 860, training accuracy 0.997   test accuracy 0.9\n",
            "step 870, training accuracy 0.987   test accuracy 0.775\n",
            "step 880, training accuracy 0.992   test accuracy 0.8625\n",
            "step 890, training accuracy 0.996   test accuracy 0.9\n",
            "step 900, training accuracy 0.992   test accuracy 0.825\n",
            "step 910, training accuracy 0.996   test accuracy 0.8875\n",
            "step 920, training accuracy 0.996   test accuracy 0.7875\n",
            "step 930, training accuracy 0.991   test accuracy 0.825\n",
            "step 940, training accuracy 1   test accuracy 0.925\n",
            "step 950, training accuracy 0.999   test accuracy 0.8875\n",
            "step 960, training accuracy 0.999   test accuracy 0.85\n",
            "step 970, training accuracy 0.997   test accuracy 0.925\n",
            "step 980, training accuracy 0.998   test accuracy 0.85\n",
            "step 990, training accuracy 0.998   test accuracy 0.8875\n",
            "step 1000, training accuracy 1   test accuracy 0.9\n",
            "step 1010, training accuracy 1   test accuracy 0.9\n",
            "step 1020, training accuracy 0.997   test accuracy 0.85\n",
            "step 1030, training accuracy 0.994   test accuracy 0.8\n",
            "step 1040, training accuracy 1   test accuracy 0.875\n",
            "step 1050, training accuracy 0.999   test accuracy 0.85\n",
            "step 1060, training accuracy 0.999   test accuracy 0.8125\n",
            "step 1070, training accuracy 0.998   test accuracy 0.8875\n",
            "step 1080, training accuracy 0.999   test accuracy 0.9125\n",
            "step 1090, training accuracy 0.994   test accuracy 0.85\n",
            "step 1100, training accuracy 0.998   test accuracy 0.8875\n",
            "step 1110, training accuracy 1   test accuracy 0.875\n",
            "step 1120, training accuracy 0.999   test accuracy 0.85\n",
            "step 1130, training accuracy 0.998   test accuracy 0.9125\n",
            "step 1140, training accuracy 0.999   test accuracy 0.8375\n",
            "step 1150, training accuracy 0.998   test accuracy 0.95\n",
            "step 1160, training accuracy 0.999   test accuracy 0.875\n",
            "step 1170, training accuracy 0.997   test accuracy 0.9\n",
            "step 1180, training accuracy 0.981   test accuracy 0.8\n",
            "step 1190, training accuracy 0.994   test accuracy 0.9125\n",
            "step 1200, training accuracy 0.996   test accuracy 0.8375\n",
            "step 1210, training accuracy 0.997   test accuracy 0.9375\n",
            "step 1220, training accuracy 0.997   test accuracy 0.85\n",
            "step 1230, training accuracy 0.996   test accuracy 0.8125\n",
            "step 1240, training accuracy 0.998   test accuracy 0.875\n",
            "step 1250, training accuracy 1   test accuracy 0.875\n",
            "step 1260, training accuracy 0.999   test accuracy 0.875\n",
            "step 1270, training accuracy 0.999   test accuracy 0.8375\n",
            "step 1280, training accuracy 0.999   test accuracy 0.8875\n",
            "step 1290, training accuracy 0.994   test accuracy 0.8375\n",
            "step 1300, training accuracy 1   test accuracy 0.925\n",
            "step 1310, training accuracy 0.997   test accuracy 0.95\n",
            "step 1320, training accuracy 1   test accuracy 0.925\n",
            "step 1330, training accuracy 1   test accuracy 0.9125\n",
            "step 1340, training accuracy 0.997   test accuracy 0.925\n",
            "step 1350, training accuracy 0.996   test accuracy 0.925\n",
            "step 1360, training accuracy 0.997   test accuracy 0.9375\n",
            "step 1370, training accuracy 1   test accuracy 0.8375\n",
            "step 1380, training accuracy 1   test accuracy 0.875\n",
            "step 1390, training accuracy 0.999   test accuracy 0.875\n",
            "step 1400, training accuracy 0.998   test accuracy 0.9\n",
            "step 1410, training accuracy 1   test accuracy 0.9\n",
            "step 1420, training accuracy 0.999   test accuracy 0.85\n",
            "step 1430, training accuracy 1   test accuracy 0.8875\n",
            "step 1440, training accuracy 1   test accuracy 0.85\n",
            "step 1450, training accuracy 0.998   test accuracy 0.9\n",
            "step 1460, training accuracy 0.998   test accuracy 0.85\n",
            "step 1470, training accuracy 1   test accuracy 0.875\n",
            "step 1480, training accuracy 0.999   test accuracy 0.8625\n",
            "step 1490, training accuracy 1   test accuracy 0.85\n",
            "step 1500, training accuracy 1   test accuracy 0.8375\n",
            "step 1510, training accuracy 1   test accuracy 0.8875\n",
            "step 1520, training accuracy 0.996   test accuracy 0.8375\n",
            "step 1530, training accuracy 0.999   test accuracy 0.95\n",
            "step 1540, training accuracy 0.998   test accuracy 0.8\n",
            "step 1550, training accuracy 0.999   test accuracy 0.8625\n",
            "step 1560, training accuracy 0.998   test accuracy 0.9\n",
            "step 1570, training accuracy 0.998   test accuracy 0.8625\n",
            "step 1580, training accuracy 1   test accuracy 0.825\n",
            "step 1590, training accuracy 0.999   test accuracy 0.9875\n",
            "step 1600, training accuracy 0.997   test accuracy 0.9125\n",
            "step 1610, training accuracy 0.999   test accuracy 0.875\n",
            "step 1620, training accuracy 1   test accuracy 0.9375\n",
            "step 1630, training accuracy 1   test accuracy 0.925\n",
            "step 1640, training accuracy 1   test accuracy 0.9125\n",
            "step 1650, training accuracy 1   test accuracy 0.9125\n",
            "step 1660, training accuracy 1   test accuracy 0.9\n",
            "step 1670, training accuracy 1   test accuracy 0.8625\n",
            "step 1680, training accuracy 1   test accuracy 0.9125\n",
            "step 1690, training accuracy 0.997   test accuracy 0.8875\n",
            "step 1700, training accuracy 1   test accuracy 0.8375\n",
            "step 1710, training accuracy 0.997   test accuracy 0.9\n",
            "step 1720, training accuracy 0.994   test accuracy 0.9375\n",
            "step 1730, training accuracy 0.988   test accuracy 0.975\n",
            "step 1740, training accuracy 1   test accuracy 0.8625\n",
            "step 1750, training accuracy 0.995   test accuracy 0.875\n",
            "step 1760, training accuracy 0.988   test accuracy 0.9125\n",
            "step 1770, training accuracy 0.997   test accuracy 0.875\n",
            "step 1780, training accuracy 1   test accuracy 0.925\n",
            "step 1790, training accuracy 0.999   test accuracy 0.8625\n",
            "step 1800, training accuracy 1   test accuracy 0.8375\n",
            "step 1810, training accuracy 0.994   test accuracy 0.9125\n",
            "step 1820, training accuracy 0.999   test accuracy 0.8375\n",
            "step 1830, training accuracy 0.998   test accuracy 0.8875\n",
            "step 1840, training accuracy 0.999   test accuracy 0.8625\n",
            "step 1850, training accuracy 0.998   test accuracy 0.8375\n",
            "step 1860, training accuracy 1   test accuracy 0.95\n",
            "step 1870, training accuracy 0.998   test accuracy 0.85\n",
            "step 1880, training accuracy 1   test accuracy 0.925\n",
            "step 1890, training accuracy 0.999   test accuracy 0.875\n",
            "step 1900, training accuracy 0.999   test accuracy 0.8\n",
            "step 1910, training accuracy 0.998   test accuracy 0.9\n",
            "step 1920, training accuracy 0.997   test accuracy 0.825\n",
            "step 1930, training accuracy 0.998   test accuracy 0.9375\n",
            "step 1940, training accuracy 0.99   test accuracy 0.8625\n",
            "step 1950, training accuracy 0.996   test accuracy 0.9375\n",
            "step 1960, training accuracy 1   test accuracy 0.825\n",
            "step 1970, training accuracy 0.997   test accuracy 0.9\n",
            "step 1980, training accuracy 0.997   test accuracy 0.925\n",
            "step 1990, training accuracy 1   test accuracy 0.9125\n",
            "step 2000, training accuracy 0.995   test accuracy 0.925\n",
            "step 2010, training accuracy 1   test accuracy 0.875\n",
            "step 2020, training accuracy 1   test accuracy 0.9125\n",
            "step 2030, training accuracy 0.998   test accuracy 0.875\n",
            "step 2040, training accuracy 1   test accuracy 0.925\n",
            "step 2050, training accuracy 0.999   test accuracy 0.9\n",
            "step 2060, training accuracy 1   test accuracy 0.8625\n",
            "step 2070, training accuracy 0.999   test accuracy 0.9125\n",
            "step 2080, training accuracy 1   test accuracy 0.9\n",
            "step 2090, training accuracy 1   test accuracy 0.875\n",
            "step 2100, training accuracy 1   test accuracy 0.925\n",
            "step 2110, training accuracy 1   test accuracy 0.85\n",
            "step 2120, training accuracy 0.999   test accuracy 0.8875\n",
            "step 2130, training accuracy 0.998   test accuracy 0.9125\n",
            "step 2140, training accuracy 0.999   test accuracy 0.8875\n",
            "step 2150, training accuracy 1   test accuracy 0.8875\n",
            "step 2160, training accuracy 0.995   test accuracy 0.9625\n",
            "step 2170, training accuracy 1   test accuracy 0.9125\n",
            "step 2180, training accuracy 0.995   test accuracy 0.825\n",
            "step 2190, training accuracy 1   test accuracy 0.8625\n",
            "step 2200, training accuracy 0.999   test accuracy 0.9\n",
            "step 2210, training accuracy 0.997   test accuracy 0.9\n",
            "step 2220, training accuracy 0.999   test accuracy 0.8\n",
            "step 2230, training accuracy 1   test accuracy 0.9125\n",
            "step 2240, training accuracy 0.998   test accuracy 0.8625\n",
            "step 2250, training accuracy 1   test accuracy 0.875\n",
            "step 2260, training accuracy 0.998   test accuracy 0.95\n",
            "step 2270, training accuracy 1   test accuracy 0.8875\n",
            "step 2280, training accuracy 1   test accuracy 0.9125\n",
            "step 2290, training accuracy 1   test accuracy 0.875\n",
            "step 2300, training accuracy 1   test accuracy 0.8375\n",
            "step 2310, training accuracy 0.986   test accuracy 0.9625\n",
            "step 2320, training accuracy 0.994   test accuracy 0.825\n",
            "step 2330, training accuracy 0.999   test accuracy 0.9375\n",
            "step 2340, training accuracy 0.999   test accuracy 0.9\n",
            "step 2350, training accuracy 0.999   test accuracy 0.9125\n",
            "step 2360, training accuracy 0.999   test accuracy 0.9625\n",
            "step 2370, training accuracy 0.991   test accuracy 0.8625\n",
            "step 2380, training accuracy 0.99   test accuracy 0.9\n",
            "step 2390, training accuracy 0.993   test accuracy 0.925\n",
            "step 2400, training accuracy 1   test accuracy 0.9125\n",
            "step 2410, training accuracy 1   test accuracy 0.9375\n",
            "step 2420, training accuracy 0.998   test accuracy 0.8875\n",
            "step 2430, training accuracy 1   test accuracy 0.9375\n",
            "step 2440, training accuracy 0.999   test accuracy 0.8625\n",
            "step 2450, training accuracy 1   test accuracy 0.9\n",
            "step 2460, training accuracy 1   test accuracy 0.9125\n",
            "step 2470, training accuracy 0.999   test accuracy 0.8875\n",
            "step 2480, training accuracy 1   test accuracy 0.95\n",
            "step 2490, training accuracy 0.998   test accuracy 0.8625\n",
            "step 2500, training accuracy 1   test accuracy 0.85\n",
            "step 2510, training accuracy 0.999   test accuracy 0.925\n",
            "step 2520, training accuracy 1   test accuracy 0.875\n",
            "step 2530, training accuracy 1   test accuracy 0.8625\n",
            "step 2540, training accuracy 1   test accuracy 0.9375\n",
            "step 2550, training accuracy 0.997   test accuracy 0.9125\n",
            "step 2560, training accuracy 0.999   test accuracy 0.8375\n",
            "step 2570, training accuracy 1   test accuracy 0.9125\n",
            "step 2580, training accuracy 1   test accuracy 0.9125\n",
            "step 2590, training accuracy 0.999   test accuracy 0.875\n",
            "step 2600, training accuracy 1   test accuracy 0.8875\n",
            "step 2610, training accuracy 1   test accuracy 0.8625\n",
            "step 2620, training accuracy 0.999   test accuracy 0.875\n",
            "step 2630, training accuracy 1   test accuracy 0.9\n",
            "step 2640, training accuracy 0.999   test accuracy 0.8875\n",
            "step 2650, training accuracy 1   test accuracy 0.875\n",
            "step 2660, training accuracy 1   test accuracy 0.8875\n",
            "step 2670, training accuracy 1   test accuracy 0.925\n",
            "step 2680, training accuracy 1   test accuracy 0.85\n",
            "step 2690, training accuracy 1   test accuracy 0.95\n",
            "step 2700, training accuracy 1   test accuracy 0.825\n",
            "step 2710, training accuracy 0.999   test accuracy 0.9625\n",
            "step 2720, training accuracy 0.999   test accuracy 0.8875\n",
            "step 2730, training accuracy 0.998   test accuracy 0.9\n",
            "step 2740, training accuracy 1   test accuracy 0.8875\n",
            "step 2750, training accuracy 0.999   test accuracy 0.875\n",
            "step 2760, training accuracy 1   test accuracy 0.8625\n",
            "step 2770, training accuracy 1   test accuracy 0.925\n",
            "step 2780, training accuracy 1   test accuracy 0.925\n",
            "step 2790, training accuracy 1   test accuracy 0.8875\n",
            "step 2800, training accuracy 1   test accuracy 0.8875\n",
            "step 2810, training accuracy 1   test accuracy 0.825\n",
            "step 2820, training accuracy 1   test accuracy 0.95\n",
            "step 2830, training accuracy 0.999   test accuracy 0.9\n",
            "step 2840, training accuracy 1   test accuracy 0.8875\n",
            "step 2850, training accuracy 1   test accuracy 0.8875\n",
            "step 2860, training accuracy 0.999   test accuracy 0.8875\n",
            "step 2870, training accuracy 1   test accuracy 0.9125\n",
            "step 2880, training accuracy 1   test accuracy 0.8625\n",
            "step 2890, training accuracy 1   test accuracy 0.8375\n",
            "step 2900, training accuracy 1   test accuracy 0.9\n",
            "step 2910, training accuracy 0.999   test accuracy 0.95\n",
            "step 2920, training accuracy 0.999   test accuracy 0.825\n",
            "step 2930, training accuracy 1   test accuracy 0.975\n",
            "step 2940, training accuracy 0.998   test accuracy 0.85\n",
            "step 2950, training accuracy 0.998   test accuracy 0.9625\n",
            "step 2960, training accuracy 0.999   test accuracy 0.8625\n",
            "step 2970, training accuracy 0.998   test accuracy 0.8875\n",
            "step 2980, training accuracy 1   test accuracy 0.8375\n",
            "step 2990, training accuracy 1   test accuracy 0.8875\n",
            "step 3000, training accuracy 1   test accuracy 0.9375\n",
            "step 3010, training accuracy 0.998   test accuracy 0.8875\n",
            "step 3020, training accuracy 1   test accuracy 0.9\n",
            "step 3030, training accuracy 1   test accuracy 0.8875\n",
            "step 3040, training accuracy 1   test accuracy 0.875\n",
            "step 3050, training accuracy 1   test accuracy 0.8875\n",
            "step 3060, training accuracy 1   test accuracy 0.95\n",
            "step 3070, training accuracy 1   test accuracy 0.8125\n",
            "step 3080, training accuracy 1   test accuracy 0.8875\n",
            "step 3090, training accuracy 1   test accuracy 0.9375\n",
            "step 3100, training accuracy 1   test accuracy 0.8875\n",
            "step 3110, training accuracy 0.998   test accuracy 0.875\n",
            "step 3120, training accuracy 1   test accuracy 0.8875\n",
            "step 3130, training accuracy 1   test accuracy 0.875\n",
            "step 3140, training accuracy 0.999   test accuracy 0.875\n",
            "step 3150, training accuracy 1   test accuracy 0.9125\n",
            "step 3160, training accuracy 1   test accuracy 0.9125\n",
            "step 3170, training accuracy 0.999   test accuracy 0.8625\n",
            "step 3180, training accuracy 1   test accuracy 0.9375\n",
            "step 3190, training accuracy 0.999   test accuracy 0.8375\n",
            "step 3200, training accuracy 0.999   test accuracy 0.925\n",
            "step 3210, training accuracy 1   test accuracy 0.9\n",
            "step 3220, training accuracy 1   test accuracy 0.9125\n",
            "step 3230, training accuracy 1   test accuracy 0.9\n",
            "step 3240, training accuracy 0.999   test accuracy 0.85\n",
            "step 3250, training accuracy 0.998   test accuracy 0.9\n",
            "step 3260, training accuracy 1   test accuracy 0.9\n",
            "step 3270, training accuracy 1   test accuracy 0.9\n",
            "step 3280, training accuracy 0.999   test accuracy 0.8875\n",
            "step 3290, training accuracy 0.999   test accuracy 0.9125\n",
            "step 3300, training accuracy 1   test accuracy 0.9\n",
            "step 3310, training accuracy 1   test accuracy 0.9125\n",
            "step 3320, training accuracy 1   test accuracy 0.925\n",
            "step 3330, training accuracy 1   test accuracy 0.9\n",
            "step 3340, training accuracy 1   test accuracy 0.8875\n",
            "step 3350, training accuracy 1   test accuracy 0.9125\n",
            "step 3360, training accuracy 1   test accuracy 0.9375\n",
            "step 3370, training accuracy 1   test accuracy 0.925\n",
            "step 3380, training accuracy 1   test accuracy 0.8875\n",
            "step 3390, training accuracy 1   test accuracy 0.875\n",
            "step 3400, training accuracy 0.999   test accuracy 0.8625\n",
            "step 3410, training accuracy 1   test accuracy 0.875\n",
            "step 3420, training accuracy 1   test accuracy 0.8875\n",
            "step 3430, training accuracy 1   test accuracy 0.925\n",
            "step 3440, training accuracy 1   test accuracy 0.9375\n",
            "step 3450, training accuracy 1   test accuracy 0.8375\n",
            "step 3460, training accuracy 1   test accuracy 0.9\n",
            "step 3470, training accuracy 1   test accuracy 0.8625\n",
            "step 3480, training accuracy 1   test accuracy 0.95\n",
            "step 3490, training accuracy 0.998   test accuracy 0.875\n",
            "step 3500, training accuracy 1   test accuracy 0.9625\n",
            "step 3510, training accuracy 1   test accuracy 0.9\n",
            "step 3520, training accuracy 1   test accuracy 0.8875\n",
            "step 3530, training accuracy 1   test accuracy 0.875\n",
            "step 3540, training accuracy 1   test accuracy 0.875\n",
            "step 3550, training accuracy 1   test accuracy 0.8375\n",
            "step 3560, training accuracy 0.999   test accuracy 0.95\n",
            "step 3570, training accuracy 0.998   test accuracy 0.8875\n",
            "step 3580, training accuracy 0.999   test accuracy 0.9375\n",
            "step 3590, training accuracy 0.999   test accuracy 0.9\n",
            "step 3600, training accuracy 0.997   test accuracy 0.85\n",
            "step 3610, training accuracy 0.999   test accuracy 0.9\n",
            "step 3620, training accuracy 1   test accuracy 0.9\n",
            "step 3630, training accuracy 1   test accuracy 0.8625\n",
            "step 3640, training accuracy 0.999   test accuracy 0.925\n",
            "step 3650, training accuracy 1   test accuracy 0.9625\n",
            "step 3660, training accuracy 1   test accuracy 0.8875\n",
            "step 3670, training accuracy 1   test accuracy 0.8625\n",
            "step 3680, training accuracy 1   test accuracy 0.8625\n",
            "step 3690, training accuracy 1   test accuracy 0.9125\n",
            "step 3700, training accuracy 0.999   test accuracy 0.875\n",
            "step 3710, training accuracy 0.999   test accuracy 0.9625\n",
            "step 3720, training accuracy 1   test accuracy 0.9125\n",
            "step 3730, training accuracy 0.999   test accuracy 0.9375\n",
            "step 3740, training accuracy 1   test accuracy 0.9125\n",
            "step 3750, training accuracy 0.999   test accuracy 0.8875\n",
            "step 3760, training accuracy 1   test accuracy 0.925\n",
            "step 3770, training accuracy 1   test accuracy 0.875\n",
            "step 3780, training accuracy 1   test accuracy 0.9625\n",
            "step 3790, training accuracy 1   test accuracy 0.875\n",
            "step 3800, training accuracy 0.998   test accuracy 0.9125\n",
            "step 3810, training accuracy 0.999   test accuracy 0.95\n",
            "step 3820, training accuracy 0.998   test accuracy 0.8375\n",
            "step 3830, training accuracy 1   test accuracy 0.875\n",
            "step 3840, training accuracy 0.997   test accuracy 0.9\n",
            "step 3850, training accuracy 1   test accuracy 0.925\n",
            "step 3860, training accuracy 1   test accuracy 0.9\n",
            "step 3870, training accuracy 0.992   test accuracy 0.85\n",
            "step 3880, training accuracy 0.995   test accuracy 0.9\n",
            "step 3890, training accuracy 1   test accuracy 0.875\n",
            "step 3900, training accuracy 0.995   test accuracy 0.9125\n",
            "step 3910, training accuracy 0.999   test accuracy 0.85\n",
            "step 3920, training accuracy 0.998   test accuracy 0.9\n",
            "step 3930, training accuracy 0.997   test accuracy 0.925\n",
            "step 3940, training accuracy 1   test accuracy 0.9375\n",
            "step 3950, training accuracy 1   test accuracy 0.8625\n",
            "step 3960, training accuracy 1   test accuracy 0.9\n",
            "step 3970, training accuracy 1   test accuracy 0.95\n",
            "step 3980, training accuracy 1   test accuracy 0.9\n",
            "step 3990, training accuracy 1   test accuracy 0.9125\n",
            "step 4000, training accuracy 1   test accuracy 0.9375\n",
            "step 4010, training accuracy 1   test accuracy 0.875\n",
            "step 4020, training accuracy 0.999   test accuracy 0.925\n",
            "step 4030, training accuracy 1   test accuracy 0.95\n",
            "step 4040, training accuracy 1   test accuracy 0.9\n",
            "step 4050, training accuracy 1   test accuracy 0.9\n",
            "step 4060, training accuracy 0.999   test accuracy 0.9375\n",
            "step 4070, training accuracy 1   test accuracy 0.925\n",
            "step 4080, training accuracy 1   test accuracy 0.875\n",
            "step 4090, training accuracy 1   test accuracy 0.9375\n",
            "step 4100, training accuracy 1   test accuracy 0.8875\n",
            "step 4110, training accuracy 1   test accuracy 0.875\n",
            "step 4120, training accuracy 1   test accuracy 0.8875\n",
            "step 4130, training accuracy 1   test accuracy 0.825\n",
            "step 4140, training accuracy 1   test accuracy 0.9625\n",
            "step 4150, training accuracy 1   test accuracy 0.9\n",
            "step 4160, training accuracy 1   test accuracy 0.8625\n",
            "step 4170, training accuracy 0.999   test accuracy 0.925\n",
            "step 4180, training accuracy 1   test accuracy 0.9\n",
            "step 4190, training accuracy 1   test accuracy 0.875\n",
            "step 4200, training accuracy 0.998   test accuracy 0.9375\n",
            "step 4210, training accuracy 0.998   test accuracy 0.95\n",
            "step 4220, training accuracy 0.978   test accuracy 0.85\n",
            "step 4230, training accuracy 0.998   test accuracy 0.9125\n",
            "step 4240, training accuracy 0.998   test accuracy 0.925\n",
            "step 4250, training accuracy 0.999   test accuracy 0.9\n",
            "step 4260, training accuracy 0.999   test accuracy 0.925\n",
            "step 4270, training accuracy 0.998   test accuracy 0.8625\n",
            "step 4280, training accuracy 1   test accuracy 0.9125\n",
            "step 4290, training accuracy 0.987   test accuracy 0.8875\n",
            "step 4300, training accuracy 1   test accuracy 0.9\n",
            "step 4310, training accuracy 0.999   test accuracy 0.925\n",
            "step 4320, training accuracy 0.998   test accuracy 0.9625\n",
            "step 4330, training accuracy 0.999   test accuracy 0.9125\n",
            "step 4340, training accuracy 0.999   test accuracy 0.9\n",
            "step 4350, training accuracy 1   test accuracy 0.9\n",
            "step 4360, training accuracy 1   test accuracy 0.8875\n",
            "step 4370, training accuracy 1   test accuracy 0.9375\n",
            "step 4380, training accuracy 1   test accuracy 0.9125\n",
            "step 4390, training accuracy 1   test accuracy 0.8875\n",
            "step 4400, training accuracy 1   test accuracy 0.9375\n",
            "step 4410, training accuracy 0.999   test accuracy 0.9375\n",
            "step 4420, training accuracy 1   test accuracy 0.8875\n",
            "step 4430, training accuracy 1   test accuracy 0.9125\n",
            "step 4440, training accuracy 1   test accuracy 0.9375\n",
            "step 4450, training accuracy 1   test accuracy 0.9\n",
            "step 4460, training accuracy 1   test accuracy 0.9125\n",
            "step 4470, training accuracy 1   test accuracy 0.875\n",
            "step 4480, training accuracy 1   test accuracy 0.925\n",
            "step 4490, training accuracy 1   test accuracy 0.95\n",
            "step 4500, training accuracy 0.999   test accuracy 0.9375\n",
            "step 4510, training accuracy 1   test accuracy 0.9625\n",
            "step 4520, training accuracy 1   test accuracy 0.95\n",
            "step 4530, training accuracy 1   test accuracy 0.9125\n",
            "step 4540, training accuracy 1   test accuracy 0.925\n",
            "step 4550, training accuracy 1   test accuracy 0.875\n",
            "step 4560, training accuracy 1   test accuracy 0.925\n",
            "step 4570, training accuracy 1   test accuracy 0.9375\n",
            "step 4580, training accuracy 1   test accuracy 0.925\n",
            "step 4590, training accuracy 1   test accuracy 0.9375\n",
            "step 4600, training accuracy 1   test accuracy 0.9\n",
            "step 4610, training accuracy 1   test accuracy 0.9375\n",
            "step 4620, training accuracy 1   test accuracy 0.8375\n",
            "step 4630, training accuracy 1   test accuracy 0.95\n",
            "step 4640, training accuracy 1   test accuracy 0.9375\n",
            "step 4650, training accuracy 1   test accuracy 0.925\n",
            "step 4660, training accuracy 0.999   test accuracy 0.925\n",
            "step 4670, training accuracy 0.999   test accuracy 0.9375\n",
            "step 4680, training accuracy 1   test accuracy 0.9\n",
            "step 4690, training accuracy 0.999   test accuracy 0.9\n",
            "step 4700, training accuracy 1   test accuracy 0.9625\n",
            "step 4710, training accuracy 1   test accuracy 0.9125\n",
            "step 4720, training accuracy 1   test accuracy 0.95\n",
            "step 4730, training accuracy 1   test accuracy 0.9375\n",
            "step 4740, training accuracy 1   test accuracy 0.9125\n",
            "step 4750, training accuracy 1   test accuracy 0.9375\n",
            "step 4760, training accuracy 1   test accuracy 0.825\n",
            "step 4770, training accuracy 1   test accuracy 0.925\n",
            "step 4780, training accuracy 0.999   test accuracy 0.9\n",
            "step 4790, training accuracy 1   test accuracy 0.975\n",
            "step 4800, training accuracy 1   test accuracy 0.9375\n",
            "step 4810, training accuracy 1   test accuracy 0.8625\n",
            "step 4820, training accuracy 1   test accuracy 0.9375\n",
            "step 4830, training accuracy 1   test accuracy 0.9125\n",
            "step 4840, training accuracy 1   test accuracy 0.925\n",
            "step 4850, training accuracy 1   test accuracy 0.9\n",
            "step 4860, training accuracy 0.999   test accuracy 0.9\n",
            "step 4870, training accuracy 1   test accuracy 0.9125\n",
            "step 4880, training accuracy 1   test accuracy 0.9625\n",
            "step 4890, training accuracy 1   test accuracy 0.9375\n",
            "step 4900, training accuracy 1   test accuracy 0.95\n",
            "step 4910, training accuracy 0.999   test accuracy 0.9125\n",
            "step 4920, training accuracy 1   test accuracy 0.9125\n",
            "step 4930, training accuracy 1   test accuracy 0.9125\n",
            "step 4940, training accuracy 0.999   test accuracy 0.95\n",
            "step 4950, training accuracy 1   test accuracy 0.9125\n",
            "step 4960, training accuracy 1   test accuracy 0.925\n",
            "step 4970, training accuracy 1   test accuracy 0.9\n",
            "step 4980, training accuracy 1   test accuracy 0.925\n",
            "step 4990, training accuracy 1   test accuracy 0.9375\n",
            "[[11  0  0  0  0  0  0  0]\n",
            " [ 0 11  0  0  0  0  0  3]\n",
            " [ 0  0 10  0  0  0  0  0]\n",
            " [ 0  0  0  6  0  0  0  0]\n",
            " [ 0  0  0  0 13  0  0  0]\n",
            " [ 0  1  0  0  0 13  0  0]\n",
            " [ 0  0  0  0  0  0  6  0]\n",
            " [ 0  0  0  1  0  0  0  5]]\n",
            "ccn test 正答率 0.95\n",
            "\n",
            "開始時刻 2019-02-06 10:54:30.251913\n",
            "終了時刻 2019-02-06 11:34:48.111516\n",
            "[11 14 10  6 13 14  6  6]\n",
            "[[11  0  0  0  0  0  0  0]\n",
            " [ 0 11  0  0  0  0  0  3]\n",
            " [ 0  0 10  0  0  0  0  0]\n",
            " [ 0  0  0  6  0  0  0  0]\n",
            " [ 0  0  0  0 13  0  0  0]\n",
            " [ 0  1  0  0  0 13  0  0]\n",
            " [ 0  0  0  0  0  0  6  0]\n",
            " [ 0  0  0  1  0  0  0  5]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}